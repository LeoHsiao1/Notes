# 部署

- 可使用官方的部署工具 kubeadm ，部署标准的 k8s 。
- 也可部署其它 k8s 发行版。它们在 k8s 的基础上封装了其它组件，比如 Web UI、网络插件。
  - minikube ：用于部署测试用途的 k8s 。
  - Rancher ：由 Rancher Labs 公司开源。
  - OpenShift ：由 Red Hat 公司开源。
  - kubesphere ：由青云公司开源。
  - KubeOperator ：由飞致云公司开源。

- 也可使用云平台托管的 k8s 发行版，不需要用户部署维护。
  - Elastic Kubernetes Service（EKS）：由 AWS 云提供。
  - Azure Kubernetes Service（AKS）：由 Azure 云提供。
  - Google Kubernetes Engine（GKE）：由 Google 云提供。
  - Tencent Kubernetes Engine（TKE）：由腾讯云提供。

## kubeadm

：一个命令行工具，用于部署标准的 k8s 集群。
- 本身不会安装 kubelet、kubectl、网络插件。

### 安装

- 用 yum 安装：
  ```sh
  # 采用阿里的镜像源，因为谷歌的镜像源需要翻墙访问
  cat <<EOF > /etc/yum.repos.d/kubernetes.repo
  [kubernetes]
  name=Kubernetes
  baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
  enabled=1
  gpgcheck=1
  repo_gpgcheck=1
  gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
  EOF

  # 安装
  yum install -y kubeadm
  ```
  - 这会同时安装依赖的 kubelet、kubectl 。

### 命令

```sh
kubeadm
        version
        config        # 管理配置。这些配置会保存为一个名为 kubeadm-config 的 ConfigMap ，位于 kube-system 命名空间
          print       # 打印配置
            init-defaults
            join-defaults

        init          # 将本机初始化为主节点
        join          # 使本机连接到主节点，加入 k8s 集群
        reset         # 撤销 init、join 命令对本机的影响

        token         # 管理 token ，用于一个节点 join 主节点时的认证
          create
            --ttl     # 有效时长，过期则自动删除。默认为 24h
          delete <token>...
          list

```

### 部署

1. 部署 k8s 时，主机需要满足以下条件：
    - 至少 2v CPU、2G RAM 。
      - 空载时，主节点的全部进程大概占用 500M 内存，而工作节点的 kubelet 占用 100M 内存。
    - 禁用 Swap 分区。
    - 每个主机的 hostname、MAC 地址不同。
    - 安装 docker 引擎。
      - dockerd 采用的 Cgroup 驱动默认为 cgroupfs ，而 k8s 默认为 systemd 。因此需要修改 dockerd 的配置，并重启 dockerd ：
        ```json
        {
          "exec-opts": ["native.cgroupdriver=systemd"]
        }
        ```
    - 主机的防火墙开通了 k8s 所需的端口 6443、10250 。
    - 在集群的一个主机上安装 kubeadm、kubectl 。
    - 在集群的每个主机上安装 kubelet ，并启动：
      ```sh
      systemctl start  kubelet
      systemctl enable kubelet
      ```

2. 下载 Docker 镜像：
    ```sh
    kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers
    ```

3. 在一个主机上执行以下命令，初始化为主节点：
    ```sh
    kubeadm init
                --config                            # 指定配置文件
                --kubernetes-version <string>       # k8s 版本。默认为最新的 stable 版本
                --image-repository registry.aliyuncs.com/google_containers  # 镜像仓库，默认为 k8s.gcr.io ，但它需要翻墙访问
                --node-name <name>                  # 指定当前节点名
                --pod-network-cidr 10.244.0.0/16    # Pod IP 的子网范围，也会被用于设置 cluster-cidr 。默认为空，不会分配 CIDR
                --service-cidr <string>             # Service IP 的子网范围，默认为 10.96.0.0/12
                --service-dns-domain <string>       # Service 的域名起点，默认为 cluster.local
    ```
    - 这会生成管理员的 kubeconfig 配置文件，将它拷贝到默认路径：
      ```sh
      mkdir -p ~/.kube
      cp /etc/kubernetes/admin.conf ~/.kube/config
      ```

4. 在其它主机上执行以下命令，加入 k8s 集群：
    ```sh
    kubeadm join 10.0.0.1:6443
          --token ****** --discovery-token-ca-cert-hash sha256:******   # 加入集群时需要使用 token 认证
          --control-plane     # 加入之后成为控制平面节点，默认是工作节点
    ```
    - 至少需要部署一个主节点和一个工作节点。
    - 默认给主节点设置了污点，不允许用作工作节点，降低主节点故障的风险。可以移除污点：
      ```sh
      kubectl taint nodes --all node-role.kubernetes.io/master-
      ```
    - 部署多个主节点时，可以实现 k8s 的高可用。
      - 此时需要给多个 kube-apiserver 实例创建一个负载均衡 IP 或 DNS ，用于访问。

5. 启用一种 CNI 网络插件：
    ```sh
    curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml | kubectl apply -f -
    ```

## kubectl

：一个命令行工具，用于管理已部署的 k8s 集群。

### 安装

- 下载二进制文件：
  ```sh
  wget https://dl.k8s.io/release/v1.23.1/bin/linux/amd64/kubectl
  sudo install kubectl /usr/local/bin/

  kubectl completion bash > /etc/bash_completion.d/kubectl  # 启用 kubectl 命令补全，保存为 bash_completion 脚本
  ```
- kubectl 命令通过访问 kube-apiserver 来控制 k8s 集群，此时需要读取一种配置文件，称为 kubeconfig 。
  - kubeconfig 配置了要连接的 kube-apiserver 地址，以及使用的集群名、命名空间、账号。
  - 默认读取 ~/.kube/config 文件作为 kubeconfig ，也可以在执行命令时加上 `--kubeconfig <path>` 参数，或声明环境变量 `export KUBECONFIG=<path>` 。

### 命令

```sh
kubectl
        # 查看集群
        cluster-info      # 显示集群信息
        version           # 显示 client 和 server 的版本
        config            # 访问 kubeconfig
            view          # 显示 kubeconfig 的内容
              --raw       # 是否显示完整内容，默认省略 token
        proxy             # 运行一个 HTTP 服务器，反向代理 apiserver
            --port=8001
            --address=127.0.0.1     # 监听的地址
            --accept-hosts='^localhost$,^127\.0\.0\.1$' # 允许 HTTP 请求采用的目标地址，采用正则匹配

        # 修改资源
        create                      # 创建资源
            -f <file>               # 指定一个配置文件。不支持指定多个文件，支持指定配置文件的 URL
            -f <dir>                # 指定一个目录，读取其下所有文件
              -R                    # 递归处理目录
        replace                     # 替换资源的配置文件。如果该资源不存在则报错
            -f <file>
            --force                 # 先删除旧资源，再创建
        apply                       # 更新资源的配置文件。如果该资源不存在则自动创建，如果该资源没有变化则显示 unchanged
            -f <file>
        patch -p '{"spec":{"unschedulable":true}}'  # 更新资源的配置文件中的指定字段，而不是修改整个配置文件
        delete                      # 删除资源
            -f <file>               # 删除配置文件中指定的资源
            pod <name>...           # 删除指定名称的 pod
            deployment <name>...    # 删除指定名称的 deployment

        # 查看资源
        describe <resource>         # 查看资源的信息，包括主要配置、event
        get <resource> [name]...    # 查看资源的信息。不指定 name 则显示这种资源的所有实例
            --kubeconfig ~/.kube/config # 指定 kubeconfig 的文件路径
            -n default              # --namespace ，指定命名空间，只查看该命名空间中的资源
            -A                      # --all-namespaces ，查看所有命名空间
            -l key1=value1,...      # --selector ，根据标签筛选
            --field-selector status.phase!=Running  # 根据字段筛选

            -o wide                 # --output ，输出格式。默认显示列表格式的简介，wide 是显示更多列
            -o name                 # 只显示名称
            -o json                 # 显示 JSON 格式的详细配置
            -o yaml                 # 显示 YAML 格式的详细配置
            -o template --template={{.spec.replicas}} # 按自定义的 Golang 模板显示

        # 管理 pod
        expose                      # 创建 service ，映射端口
        exec <pod> -- <command>     # 在 pod 中执行命令。注意在 command 之前加上分隔符 --
            -c <name>               # --container ，选择 pod 中的某个容器。默认选择第一个容器
            -it                     # 进入容器内终端
        restart <pod>...            # 重启 pod ，实际上是创建新 Pod
        rollout restart <daemonset|deployment|statefulset> <name>...  # 滚动重启 pod 。这会异步地根据 spec.strategy 创建新 pod
        scale <deployment|statefulset> <name>... --replicas=0         # 改变某个应用的 Pod 的数量
        logs <pod>                  # 查看日志
            -c <name>               # --container ，选择 pod 中的某个容器
            --all-containers        # 选择 pod 中的所有容器
            -f                      # --follow ，保持显示
            --tail 10               # 只显示最后几行。默认从头开始显示
            --timestamps            # 增加显示时间戳
            --since 1h              # 只显示最近一段时间的日志
            --since-time 2021-01-01T08:00:00Z # 只显示指定时刻开始的日志
```
- resource 类型可以是 nodes、pods、services 等。
  - 不区分单复数，比如 node 等价于 nodes 。
  - 支持通过逗号分隔符指定多个，比如 nodes,pods 。
- 例：
  ```sh
  kubectl create deployment nginx --image=nginx:1.20          # 部署一个应用
  kubectl exec nginx-6d777db949-5b77c -c nginx -it -- bash    # 进入容器内终端
  kubectl expose deployment nginx --port=80 --target-port=80  # 为应用 Nginx 创建 service ，默认为 ClusterIP 类型，并映射端口
  ```
- 关于配置文件的版本：
  - 用户修改配置文件时可以指定 resourceVersion 字段，如果与 k8s 存储的不同，则说明用户不是在最新版本上编辑，会被 k8s 拒绝。
    - 如果省略 resourceVersion ，或者采用 kubectl patch 方式，则不会检查版本。
  - kubectl apply 可能会在 annotations 中增加一个 `kubectl.kubernetes.io/last-applied-configuration` 字段，记录资源的当前配置，用于比较差异，找出更新了哪些字段。
  - Deployment 资源还会增加一个 generation 字段，用于记录版本序号。

## minikube

：一个命令行工具，用于部署单节点的 k8s 集群，常用于测试。
- 可以在本机部署多个 k8s 集群。每个 k8s 集群位于一个容器内，包含多个进程。

### 部署

1. 安装 docker
2. 下载 minikube ：
    ```sh
    wget https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    sudo install minikube-linux-amd64 /usr/local/bin/
    ```

3. 以非 root 用户部署 k8s ：
    ```sh
    useradd leo
    usermod leo -G docker
    su - leo
    minikube start
    ```

3. 在本机安装 kubectl ，或使用 minikube 内置的 kubectl ：
    ```sh
    minikube kubectl -- get pods -A
    ```

### 命令

```sh
minikube
        start                             # 部署一个 k8s 集群
            -p <name>                     # --profile ，指定 k8s 集群的名称，默认为 minikube
            --driver docker               # 驱动，默认会自动选择
            --kubernetes-version v1.2.3   # k8s 版本。默认为最新的 stable 版本
        stop
        delete          # 删除当前 k8s 集群
            -p <name>   # 指定 k8s 集群的名称
            --all       # 删除所有 k8s 集群
        pause           # 暂停运行
        unpase

        profile         # 显示当前 k8s 集群的名称
            list        # 显示所有 k8s 集群
        status
```

## Rancher

：一个 Web 网站，可以创建、管理多个 k8s 集群。
- [官方文档](https://rancher.com/docs/rancher/v2.6/en/)
- 采用 Golang 开发。
- 架构：
  - 先部署 Rancher server 。
  - 然后在一些主机上运行 Rancher agent ，连接到 server ，被 server 控制。
    - Rancher 可以在多个主机上创建、管理多个 k8s 集群，称为下游集群。也可以导入已部署的集群。
    - 当 Rancher server 故障时，下游集群依然会正常运行，可以被用户直接访问。
- Rancher 提供了多种 k8s 发行版：
  - RKE（Rancher Kubernetes Engine）：一个 k8s 发行版。包含了一个命令行工具，用于部署 k8s 。
  - k3s ：一个轻量级的 k8s 发行版。
    - 主节点只需运行 k3s server 进程，工作节点只需运行 k3s agent 进程。
    - 默认采用 sqlite3 作为数据库。

### 部署

- 用 docker 部署一个单节点的 Rancher ：
  ```sh
  docker run -d \
      -p 80:80 -p 443:443 \
      --name rancher \
      --privileged \
      rancher/rancher:v2.6.3-linux-amd64
  ```
  - 此时 Rancher 会在容器内运行一个 k3s 集群。

- 或者在 k8s 中用 helm 部署单节点的 Rancher 。也可以部署成多节点，实现高可用。

### 用法

- Rancer 增加了项目（project）的概念，用于对命名空间分组。
- Rancher 默认在 default 命名空间创建了一个 kubernetes 服务，用于反向代理 apiserver ，访问地址为 `https://10.43.0.1:443` 。

### 配置

- 在 Rancher 的 k8s 集群管理页面，可通过 UI 页面配置 k8s ，也可以通过 YAML 格式编辑更多配置参数，如下：
  ```yml
  name: test-k8s                                # k8s 集群名
  rancher_kubernetes_engine_config:
    # private_registries:                       # 可以让 Rancher 部署 k8s 组件时也采用私有的镜像仓库
    #   - is_default: true
    #     url: harbor.test.com
    services:                                   # 配置各个 k8s 组件
      kube-api:
        service_cluster_ip_range: 10.43.0.0/16
        service_node_port_range: 30000-32767
      kube-controller:
        cluster_cidr: 10.42.0.0/16              # Pod IP 的子网范围
        service_cluster_ip_range: 10.43.0.0/16  # Service IP 的子网范围
        extra_args:                             # 添加命令行参数
          node-cidr-mask-size: '24'             # 每个 Node 的子网掩码长度
        # extra_binds:
        #   - '/etc/localtime:/etc/localtime:ro'
      kubelet:
        cluster_domain: cluster.local
        cluster_dns_server: 10.43.0.10
        extra_args:
          max-pods: 110
          eviction-hard: "memory.available<100Mi,nodefs.available<10%,imagefs.available<15%,nodefs.inodesFree<5%"
  ```
