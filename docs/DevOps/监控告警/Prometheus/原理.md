# 原理

- Prometheus 的工作原理：
  - 运行一些 exporter 程序，能通过 HTTP API 输出文本格式的监控指标，称为 metrics 。
  - Prometheus 每隔 scrape_interval 时长向各个 exporter 发送一个 HTTP GET 请求，从 HTTP 响应中读取 metrics 文本，然后存储到内置的时序数据库 TSDB 中。该过程称为采集（scrape）。
  - 用户可向 Prometheus 发出查询请求，查询 TSDB 中存储的监控指标。
- 一个应用程序，只要能通过 HTTP API 输出正确格式的 metrics 文本，就可担任 exporter 。
  - 例如 Prometheus 本身也提供了 exporter 端口，执行 `curl 127.0.0.1:9090/metrics` 即可获得 metrics 。
  - Prometheus 可采集大量 exporter 。每个 exporter 通过不同的 IP:PORT 地址来区分，每个地址称为一个 target、instance 。

## scrape

- Prometheus scrape 的方式有多种：
  - exporter
    - ：最基础的方式。让程序监听一个符合 exporter 格式的 HTTP API ，由 Prometheus 定期发送 HTTP GET 请求到该 API ，采集 metrics 。
    - exporter 平时一般无事可做，收到 HTTP 请求时才动态生成一次当前时刻的 metrics ，例如统计当前的线程数。
    - 减少 scrape_interval 能提高采集频率，减小离散采样的误差，但会增加 Prometheus 和 exporter 的 CPU、带宽开销。
  - pushgateway
    - ：程序定期将 metrics 文本通过 POST 请求发送到 pushgateway ，然后 Prometheus 以 exporter 方式从 pushgateway 采集 metrics 。
  - 第三方媒介
    - ：程序定期将 metrics 文本写入文件、数据库等媒介，然后由 node_exporter 等工具收集这些 metrics ，加入自己 exporter 接口的响应中。

- Prometheus scrape 的工作流程：
  1. Prometheus 发出 HTTP 请求。
  2. HTTP 请求经过网络传输，到达 exporter 。
  3. exporter 开始统计 metrics ，生成 HTTP 响应。
  4. HTTP 响应经过网络传输，到达 Prometheus 。
  5. Prometheus 将 HTTP 响应中的 metrics 文本解析成 samples ，存入 memSeries 。

- Prometheus 会为每个 target 运行一个 scrapeLoop 循环，源代码如下：
  ```golang
  func (sl *scrapeLoop) run(errc chan<- error) {
    select {
    case <-time.After(sl.scraper.offset(sl.interval, sl.offsetSeed)): // 等待 offset 时长，才开始 scrapeLoop
    case <-sl.ctx.Done():
      close(sl.stopped)
      return
    }

    var last time.Time                    // 记录上一次执行 scrapeAndReport() 的时刻
    ticker := time.NewTicker(sl.interval) // 每隔 scrape_interval 时长采集一次
    defer ticker.Stop()

  mainLoop:
    for {
      scrapeTime := time.Now().Round(0)   // 记录当前时刻，之后会赋值给 sample.timestamp
      last = sl.scrapeAndReport(last, scrapeTime, errc) // 采集指标，并存入 memSerie
      ...
    }
    ...
  }
  ```
  - Prometheus 刚启动时，不会同时采集所有 target ，否则会造成很大的瞬时负载。相反，为了错峰，Prometheus 会为每个 target 配置一个随机的 offset ，等待 offset 时长之后才开始 scrapeLoop 。
    - 例如 scrape_interval 为 30s 时，`go_goroutines{instance="10.0.0.1:9090", job="prometheus"}` 的 scrapeTime 分别是第 2、32、62 秒，`go_goroutines{instance="10.0.0.2:9090", job="prometheus"}` 的 scrapeTime 分别是第 5、35、65 秒。
    - offset 由 target、Prometheus 的哈希值决定。这样能避免一个 Prometheus 同时采集所有 target 、多个 Prometheus 同时采集同一个 target 。
  - Prometheus 会记录从发出 HTTP 请求，到存入 memSeries 的耗时，称为 duration 。受网络延迟、exporter 运行速度的影响，duration 可能经常变化。
  - Prometheus 记录的 sample.timestamp 是发出 HTTP 请求的时刻即 scrapeTime ，并不是 exporter 生成 metrics 的时刻。因此 Prometheus 不能准确测量 metrics 的时刻。
  - scrapeTime 会以 scrape_interval 为单位递增，不受 duration 影响。即使某次 scrape 超时，下一次 scrape 依然会按时进行。

### metrics

- exporter 输出的 metrics 文本示例：
  ```sh
  # HELP go_goroutines Number of goroutines that currently exist.
  # TYPE go_goroutines gauge
  go_goroutines{instance="10.0.0.1:9090", job="prometheus"}   80
  go_goroutines{instance="10.0.0.2:9090", job="prometheus"}   90
  ```
  - `# HELP <metric_name> <comment>` 行用于声明该指标的注释，可以省略。
  - `# TYPE <metric_name> <type>` 行用于声明该指标的类型。
  - 每行指标的格式为 `<metric_name>{<label_name>=<label_value>, ...}  metric_value` ，先是指标名称、标签，然后在任意个空格之后声明指标值。
    - metric_name 必须匹配正则表达式 `[a-zA-Z_:][a-zA-Z0-9_:]*` ，一般通过 Recording Rules 定义的指标名称才包含冒号 `:` 。
    - exporter 生成多条用途相同的监控指标时，建议采用同一个 metric_name 、不同的 label_value ，然后通过 labels 来筛选。
    - label_value 只能用双引号 " 作为定界符，不能用单引号 ' 。
    - label_value 可包含 Unicode 字符。
    - metric_value 只能是数值，不支持 string 类型。
  - exporter 输出的 metrics 中可包含多行指标。
    - 相同 metric_name 的指标放在一起，放在一行 TYPE 之下。
    - 每行末尾不能存在空格，否则会被解析成最后一个字段。
    - 每行末尾要有换行符，最后一行也需要换行。

- 根据数据结构，对 metrics 分类：
  - 标量（scalar）
    - ：一个数值，属于 float 数据类型。
    - 例如数值 `1` 属于 scalar 。
    - scalar 只有 value ，没有 timestamp、labels 信息，因此不能进行 delta() 等函数运算，常用于与 vector 进行算术运算。
  - 瞬时矢量（instant vector）
    - ：默认类型的 vector ，包含一组 time series 。
    - 例如在 Prometheus 的 Graph 页面，查询 `go_goroutines{job="prometheus"}` 会显示多条曲线，即多个 time series ，属于一个 vector 。
    - 一个 time series 在每个采样时刻只有一个 sample ，而一个 vector 在每个采样时刻有一组 sample 。
  - 范围矢量（range vector）
    - ：instant vector 的每个 sample 只包含一对 timestamp、value ，而 range vector 的每个 sample 包含一段时间范围内的多对 timestamp、value 。
    - 例如 `go_goroutines{job="prometheus"}[1m]` 属于 range vector ，先从 TSDB 中读取 instant vector 形式的 sample ，然后转换成 range vector 形式的 sample 。其中单个 sample 如下：
      ```json
      {
          "metric": {
              "__name__": "go_goroutines",
              "instance": "10.0.0.1:9090",
              "job": "prometheus",
          },
          "values": [
              [1656109032.131, "80"],
              [1656109062.503, "82"],
          ]
      }
      ```
    - range vector 不能在 Graph 页面直接显示成曲线，主要用途是作为 delta() 等函数的输入。

- 根据用途，对 metrics 分类：
  - Counter
    - ：计数器，取值单调递增。
  - Gauge
    - ：仪表，取值没有单调性，可以自由增减。
  - Histogram
    - ：直方图。将时间平均分成一段段区间，将每段时间内的多个 samples 取平均值再返回（这会增加 Prometheus 的 CPU 开销），相当于从散点图变成直方图。
    - 例如 `prometheus_http_request_duration_seconds_count{}  10` 表示 HTTP 请求的样本总数有 10 个。
    - 例如 `prometheus_http_request_duration_seconds_sum{}  0.1` 表示 HTTP 请求的耗时总和为 0.1s 。
    - 例如 `prometheus_http_request_duration_seconds_bucket{le="60"}  10` 表示 HTTP 请求中，耗时低于 60s 的有 10 个。
  - Summary
    - ：汇总。将所有 samples 按取值从小到大排列，然后返回其中几个关键位置的 samples 的值（由 exporter 计算），相当于正态分布图。
    - 例如 `..._count`、`..._sum` 后缀。
    - 例如 `go_gc_duration_seconds{quantile="0.5"}  0.001` 表示全部 gc 耗时中，排在 50% 位置处的值（即中位数）。
    - 例如 `go_gc_duration_seconds{quantile="0.75"}  0.001` 表示全部 gc 耗时中，排在 75% 位置处的值。
    - 例如  `go_gc_duration_seconds{quantile="1"}  0.002` 表示全部 gc 耗时中，排在 100% 位置处的值，即最大值。
  - exemplar
    - ：在 metrics 之后附加 traceID 等信息，便于链路追踪。
    - 该功能默认禁用。

### samples

- Prometheus 会将采集到的每行 metric 文本，转换成一种数据结构：采样点（sample），又称为数据点（point）。这样便于写入 TSDB 时序数据库。
  - 例如 `go_goroutines{instance="10.0.0.1:9090", job="prometheus"}   80` 这行 metric ，会转换成一个 sample ，表示成 JSON 格式如下：
    ```json
    {
        "metric": {                       // 该 metric 的 label-value set
            "__name__": "go_goroutines",  // 将 metric_name 记录为内置标签 __name__
            "instance": "10.0.0.1:9090",
            "job": "prometheus",
        },
        "value": [
            1656109032.131,               // timestamp ，单位为秒，保留三位小数到毫秒
            "80"                          // value
        ]
    }
    ```
  - 假设在多个时刻采样一次 `go_goroutines{instance="10.0.0.1:9090", job="prometheus"}` 的值，得到多个 sample 。
    - 这些 sample 的 label-value set 相同，属于同一条指标。
    - 将这些 sample 按时间顺序组成一个数组，就得到了一个时间序列（time series），可用于监控指标取值随时间变化的趋势。
  - 同一条指标的多个 sample 具有相同的 label-value set ，因此只需记录一份 label-value set ，再给每个 sample 记录一份时间戳、取值。数据结构如下：
    ```golang
    type sample struct {
        timestamp  int64
        value  float64
    }
    ```
   这些 sample 的时间戳前缀相同，因此存储到磁盘时还可以压缩。

## TSDB

### 目录结构

- Prometheus 内置的时序数据库 TSDB 默认存储在 `${prometheus}/data/` 目录下，目录结构如下：
  ```sh
  data/
  ├── 01E728KFZWGDM7HMY6M2D26QJD/   # 一个 block 目录
  │   ├── chunks
  │   │   ├── 000001                # 持久化保存的数据文件，已压缩
  │   │   └── 000002
  │   ├── index                     # 索引
  │   ├── meta.json                 # 元数据，记录该 block 的 minTime、maxTime、numSeries 等信息
  │   └── tombstones                # 墓碑
  ├── 01BKGTZQ1HHWHV8FBJXW1Y3W0K/
  ├── chunks_head/
  ├── lock                          # Prometheus 启动时会在 data 目录下创建一个 lock 文件，禁止其它 Prometheus 进程同时读写 TSDB
  ├── queries.active
  └── wal/
      ├── 00000003                  # 预写日志文件，未压缩
      ├── 00000004
      └── checkpoint.000002/        # 检查点
  ```

### wal

- Prometheus 采集到一批 metrics 数据时，首先将它们暂存在内存中。同时备份到磁盘的 wal 目录下，从而避免 Prometheus 终止时丢失内存中的数据。
  - wal 目录用于保存预写日志（Write Ahead Log ，WAL），分为多个文件（称为 segment ），文件名是从 0 开始递增的编号。
  - 每个文件的最大体积为 128MB ，当一个文件写满数据时就会创建一个新文件。
  - Prometheus 重启时，会读取 wal 目录，从而恢复数据到内存中。该过程通常耗时几十秒，Prometheus 会打印一条日志：`Replaying WAL, this may take a while`

- wal 目录下的每个 segment 文件会保存 2 小时以上。
  - 每隔 2 小时，Prometheus 会执行一次持久化：创建一个随机编号的 block 目录，将内存中 2 小时范围内的数据压缩之后保存到 `${block}/chunks/` 目录下。
  - 如果持久化成功，则会删除 wal 目录下开头 2 小时范围内的一连串 segment ，并创建一个新的 checkpoint ，用于记录最后一个删除的 segment 的编号。

### memSeries

- 对于采集到的每个 time series ，Prometheus 会在内存中分别创建一个数据结构 memSeries 来保存数据。如下：
  ```golang
  type memSeries struct {
      ref  chunks.HeadSeriesRef     // 当前的 seriesId
      lset labels.Labels            // 当前 time series 的 label-value set
      mmappedChunks []*mmappedChunk // 指向磁盘 data/chunks_head/ 目录下的所有 chunks ，以 MMAP 方式读取
      headChunk     *memChunk       // 指向内存中的 headChunk
      ...
  }
  ```
  - 一个 time series 包含多个 sample ，保存在同一个 memSeries 中。该 memSeries 会保存一份 label-value set ，被这些 sample 共享，然后在 chunks 空间中保存各个 sample 的 timestamp、value 。
  - 新采集一个 sample 时，
    - 如果它的 seriesId 匹配已有的某个 memSeries ，则以 append 方式写入该 memSeries 。否则，创建一个新的 memSeries 。
    - 将 sample 写入 memSeries 的同时，也会写入 wal 预写日志文件，防止丢失。

- 对于每个 time series ，计算其 label-value set 的哈希值，记作 seriesId 。
  - seriesId 是 time series 在 TSDB 数据库的主键、唯一索引，又称为 series ref 。
  - Prometheus 采集、查询时涉及的 seriesId 基数越大，在内存中创建的 memSeries 越多，导致 CPU、内存开销越多。
    - 采集时，平均每个 time series 占用 10KB 内存，可用 `process_resident_memory_bytes / prometheus_tsdb_head_series` 估算。
    - 因此，exporter 应该避免在 label-value set 中包含一些经常变化的值，比如 url、time 。
    - 查询时，除了减少 seriesId 基数，用户还应该减小时间范围。查询的时间范围越大，从磁盘读取的 chunks 越多，导致耗时、内存开销越多。

- 每个 time series 通常每隔 scrape_interval 时长采集一个 sample ，因此每个 memSeries 中保存的 sample 逐渐增多，占用内存也增多，那么什么时候将内存中数据保存到磁盘呢？
  - 每个 memSeries 会创建多个 chunk 空间，每个 chunk 用于保存大约 120 个 sample （此时压缩效率最好）。
  - 每个 memSeries 只有最新的一个 chunk 可供写入新数据，称为 headChunk 。
  - 当 headChunk 写入大约 120 个 sample 时，就会以 MMAP 方式 flush 到磁盘的 `data/chunks_head/` 目录下，然后在内存中创建一个新的 headChunk 。
    - 采用 MMAP 方式，既可以减少大量内存开销，又可以在之后转存为 block 时快速读取这些文件。

- `data/chunks_head/` 目录下保存了多个数据文件，每个文件的最大体积为 128MB 。
  - 每个文件可存储多个 chunk 数据，每个 chunk 的内容分为以下几部分：
    ```sh
    series ref <8 byte>     # 该 chunk 所属的 seriesId
    mint <8 byte, uint64>   # 最小时间戳。表示该 chunk 保存的这些 sample 所处的时间范围
    maxt <8 byte, uint64>   # 最大时间戳
    encoding <1 byte>       # data 部分的压缩格式
    len <uvarint>           # data 部分的长度
    data <bytes>            # 将一些 sample 的 timestamp、value 数据压缩之后保存在此
    CRC32 <4 byte>          # 对上述数据的校验码
    ```
  - 这些文件，加上内存中每个 memSeries 的 headChunk ，组成了 head_block 。
    - head_block 是 TSDB 中最新的一个 block ，保存在内存中。只有 head_block 可供写入新数据，其它 block 都持久化保存在磁盘中，不可写入数据。
  - 这些文件会保存 2 小时以上。每隔 2 小时，Prometheus 会执行一次持久化：
    - 将 `data/chunks_head/` 目录下开头 2 小时范围内的一连串文件，压缩为一个新的 block 目录。
    - 更新 wal 目录的 checkpoint 。
    - 在内存中执行垃圾收集，删除没有 chunk 数据的 memSeries 。这样能避免某些 time series 长时间没有新增 sample ，却依然占用内存。

### block

- 每个 block 目录最初保存 2 小时范围的数据、索引，但之后可能经过合并，保存更长时间范围的数据、索引。
  - `${block}/chunks/` 目录用于保存压缩之后的 sample 数据，分为多个文件，每个文件包含多个 chunk 。文件名是从 0 开始递增的编号，每个文件的最大体积为 512MB 。

- 因为顺序读写磁盘的速度比随机读写快多倍，Prometheus 一般不会修改 block ，只允许读取。
  - 以下情况会创建新的 block ，删除旧的 block ：
    - 每个 block 存在一段时间后可能被进一步压缩。
    - 时间相邻的几个 block 可能被合并为一个 block 。
  - 当用户请求删除某些 samples 数据时，Prometheus 不会立即修改 block 的数据文件，而是在 tombstones 文件中标记哪些数据待删除。等下一次压缩、合并 block 时，才从磁盘删除这些数据。
    - tombstones 用于标记删除某些 seriesId 在某些时间范围内的 sample 。
    - 查询 block 时，会忽略 tombstones 标记的数据。

### index

- 每个 block 目录下分别建立了一个 index 索引文件，记录以下信息：
  - 正排索引：记录该 block 存储的所有 time series ，每个 time series 记录以下信息：
    - seriesId
    - label-value set ：该 time serie 包含哪些标签、值。
    - chunks ：该 time series 的 sample 数据存储在哪些 chunks 中，每个 chunk 定位到 `${block}/chunks/<id>` 文件中的某个 offset 处。
  - 倒排索引：从每个 label-value 向 seriesId 建立倒排索引。
    - 例如记录：含有标签 `__name__="go_goroutines"` 的 seriesId 有 11、12、13 等，含有标签 `job="prometheus"` 的 seriesId 有 11、21、31 等。

- index 文件可进行三种基本查询：
  ```golang
  LabelNames()        // 返回 block 中所有不同的 label_name
  LabelValues(name)   // 返回某个 label_name 所有不同的 label_value
  Select([]matcher)   // 返回 block 中匹配 matcher 的所有 sample 数据
  ```
  - 当用户在 Promtheus 的 Web 页面上键入查询表达式时，会自动基于 `LabelNames()`、`LabelValues(name)` 显示 autocomplete 提示。
  - 当用户执行查询表达式时，Prometheus 会在底层转换成多个 matcher ，基于 `Select([]matcher)` 查询数据。
  - 一个 matcher 同时只能查询一个 label_name ，有四种匹配条件：
    ```sh
    labelName="<value>"     # 字符串匹配
    labelName!="<value>"    # 反字符串匹配
    labelName=~"<regex>"    # 正则匹配。这里要求正则表达式匹配 label_value 整个字符串，相当于 ^<regex>$
    labelName!~"<regex>"    # 反正则匹配
    ```

- 例如查询 `delta(go_goroutines{instance="10.0.0.1:9090", job="prometheus"}[1m])` 时，Prometheus 的处理流程如下：
  1. 查询的时间范围为最近 1m ，因此在 TSDB 中找到在该时间范围内的所有 block 。
  2. 遍历上述 block ，读取 index 文件并进行以下查询：
      1. 查询含有标签 `__name__="go_goroutines"` 的所有 seriesId 。
      2. 查询含有标签 `instance="10.0.0.1:9090"` 的所有 seriesId 。
      3. 查询含有标签 `job="prometheus"` 的所有 seriesId 。
      4. 对上述几组 seriesId 取交集，筛选出当前 block 中同时满足上述标签的所有 seriesId ，暂存在内存中。
      5. 查询下一个 block 。
  3. 遍历上述 seriesId ，找到它们的 sample 数据存储在 `${block}/chunks/` 目录下的哪些文件中，从磁盘读取这些 sample 的 timestamp、value ，载入内存。
  4. 用 delta() 函数计算上述 sample 。

## PromQL

- Prometheus 提供了一种查询语言 PromQL ，用于查询 TSDB 中的 samples ，还可进行加工计算。
- 用户可在 Prometheus 的 Web 页面执行 PromQL 查询表达式，可显示成两种图表：
  - Table
    - ：查询某个时刻的 samples ，然后显示成列表。
    - 此时前端会向 Prometheus 发出 /api/v1/query 请求。
  - Graph
    - ：查询某段时间范围内的所有 samples ，然后以时间为 x 轴显示成曲线图。
    - 此时前端会向 Prometheus 发出 /api/v1/query_range 请求。
    - 显示曲线图需要加载很多 samples ，开销大，可能导致 Web 页面卡顿。

### 查询表达式

- 编写 PromQL 查询表达式时，至少要包含一个 metric_name 或 label-value ，用于筛选 samples 。语法示例如下：
  ```sh
  go_goroutines                                   # 查询具有该名称的指标
  {job="prometheus"}                              # 查询具有指定标签值的指标
  {job!~'_.*', job!~'prometheus'}                 # 支持查询重复的指标名
  {__name__="go_goroutines", job='prometheus'}    # 通过内置标签 __name__ 可匹配指标名

  go_goroutines{job="prometheus"}                 # 查询具有该名称、该标签值的指标
  go_goroutines{job!="prometheus"}                # 要求具有 job 标签，且值不等于 prometheus
  go_goroutines{job=""}                           # 要求 job 标签的值为空字符串（这等价于不具有 job 标签）
  go_goroutines{job!=""}                          # 要求具有 job 标签且值不为空
  go_goroutines{job=~`prometheu\w`}               # 正则匹配
  go_goroutines{job!~`prometheu\w`}               # 反正则匹配

  go_goroutines{job="prometheus"} offset 1m       # 默认是查询当前时刻的 samples ，使用 offset 则是查询一段时间之前的 samples ，相当于在一段时间之前执行该查询表达式
  sum(go_goroutines{job="prometheus"} offset 1m)  # 使用函数时，offset 符号要放在函数括号内
  ```
  - 用 # 声明单行注释。
  - 将字符串用反引号包住时，不会让反斜杠转义。
  - 查询表达式不能为空的 `{}` ，同理也不能使用 `{__name__=~".*"}` 选中所有指标。

- 以上查询表达式得到的是 instant vector ，以下查询表达式得到的是 range vector ：
  ```sh
  go_goroutines{job="prometheus"}[1m]             # 查询以当前时刻为基准，过去 1m 时间范围内的所有 samples
  go_goroutines{job="prometheus"}[10m:1m]         # 在过去 10m 时间范围内，每隔 1m 时长取一个 sample 返回
  ```

- PromQL 中时间的取值必须是正整数，支持以下时间单位：
  ```sh
  s     # 秒
  m     # 分钟
  h     # 小时
  d     # 天
  w     # 周
  y     # 年
  ```

### 运算符

- 运算符的优先级从高到低如下，同一优先级的采用左结合性：
  ```sh
  ^
  * /  %
  + -
  == != <= < >= >
  and unless
  or
  ```

- 可以进行如下算术运算：
  ```sh
  go_goroutines + 1   # 加
  1 - 2               # 减
  1 * 2               # 乘
  1 / 3               # 除法（小数点后会保留十多位）
  1 % 3               # 取模
  2 ^ 3               # 取幂
  ```
  - 只能对指标的值进行运算，不能对标签的值进行运算。
  - 关于 0 的除法运算：
    ```sh
    0 / 任意正数    # 结果为 0
    0 / 任意负数    # 结果为 -0
    0 / 0          # 结果为 NaN
    任意正数 / 0    # 结果为 +Inf
    任意负数 / 0    # 结果为 -Inf
    ```
    - 对于特殊值，可以用 expression > 0 等方式过滤掉。

- 可以进行如下比较运算：
  ```sh
  go_goroutines == 2
  go_goroutines != 2
  go_goroutines >  2  # 返回大于 2 的部分曲线
  go_goroutines <  2
  go_goroutines >= 2
  go_goroutines <= 2
  ```
  - 比较运算默认是过滤掉不符合条件的数据。
  - 如果在比较运算符之后加上关键字 bool ，比如 `1 == bool 2` ，就会返回比较运算的结果，用 1、0 分别表示 true、flase 。

- 矢量之间可以进行如下集合运算：
  ```sh
  go_goroutines{job='prometheus'} and     go_goroutines                     # 交集（返回两个矢量中标签列表相同的时间序列，取第一个矢量中的值）
  go_goroutines{job='prometheus'} or      go_goroutines{job='prometheus'}   # 并集（将两个矢量中的所有时间序列合并，如果存在标签列表重复的时间序列，则取第一个矢量中的值）
  go_goroutines{job='prometheus'} unless  go_goroutines{job!='prometheus'}  # 补集（返回在第一个矢量中存在、但在第二个矢量中不存在的时间序列）
  ```

- 矢量之间进行运算时，默认只会对两个矢量中标签列表相同的时间序列（即标签名、标签值完全相同）进行运算。如下：
  ```sh
  go_goroutines - go_goroutines
  go_goroutines{instance="10.0.0.1:9100"} - go_goroutines                            # 两个矢量中存在匹配的时间序列，可以进行运算
  go_goroutines{instance="10.0.0.1:9100"} - go_goroutines{instance="10.0.0.2:9100"}  # 两个矢量中不存在匹配的时间序列，因此运算结果为空
  go_goroutines{instance="10.0.0.1:9100"} - go_gc_duration_seconds_sum{instance="10.0.0.1:9100"}  # 指标名不同，但标签列表相同，依然可以运算
  ```
  可以按以下格式，将两个只有部分标签匹配的时间序列进行运算：
  ```sh
  go_goroutines{instance="10.0.0.1:9100"} - on(job) go_goroutines{instance="10.0.0.2:9100"}             # 只考虑 job 标签，则能找到匹配的时间序列
  go_goroutines{instance="10.0.0.1:9100"} - ignoring(instance) go_goroutines{instance="10.0.0.2:9100"}  # 忽略 instance 标签，则能找到匹配的时间序列
  go_goroutines{instance="10.0.0.1:9100"} and on() hour() == 8                                          # 只获取 8 点时的时间序列
  ```
  以上只是对时间序列进行一对一匹配，可以按下格式进行一对多的匹配：
  ```sh
  go_goroutines - on() group_left vector(1)       # 不考虑任何标签，用右边的一个时间序列匹配左边的多个时间序列，分别进行运算，相当于 go_goroutines - 1
  vector(1)     + on() group_right go_goroutines  # group_right 表示用左边的一个时间序列匹配右边的多个时间序列，group_left 则相反
  ```

### 函数

- 矢量与标量的转换：
  ```sh
  vector(1)                 # 输入标量，返回一个矢量
  scalar(vector(1))         # 输入一个 time series ，返回每个采样时刻处的标量值
  ```

- 关于时间：
  ```sh
  time()                    # 返回当前的 Unix 时间戳（标量），单位为秒
  timestamp(vector(1))      # 返回矢量中每个数据点的时间戳（矢量）

  # 以下函数用于获取某个时间信息（注意为 UTC 时区）。可以输入一个时间矢量，不输入时默认采用当前时间，比如 hour( timestamp(vector(1)) )
  minute([vector])          # 分钟，取值为 0~59
  hour  ([vector])          # 小时，取值为 0~23
  month ([vector])          # 月份，取值为 1~31
  year  ([vector])          # 年份
  day_of_month([vector])    # 该月中的日期，取值为 1~31
  day_of_week ([vector])    # 周几，取值为 0~6 ，其中 0 表示周日
  ```
  例：
  ```sh
  hour() == 16 and minute() < 5   # 仅在 UTC+8 时区每天的前 5 分钟，表达式结果不为空，采取第一段的值，即 16
  ```

- 关于排序：
  ```sh
  sort(go_goroutines)       # 按指标值升序排列
  sort_desc(go_goroutines)  # 按指标值降序排列
  ```
  - 在 Prometheus 的 Table 页面，显示的指标默认是无序的，只能通过 sort() 函数按指标值排序。不支持按 label 进行排序。
  - 在 Graph 页面，显示的图例是按第一个标签的值进行排序的，且不受 sort() 函数影响。

- 修改矢量的标签：
  ```sh
  # 给矢量 go_goroutines 添加一个标签，其名为 new_label ，其值为 instance、job 标签的值的组合，用 , 分隔
  label_join(go_goroutines, "new_label", ",", "instance", "job")

  # 正则匹配。给矢量 go_goroutines 添加一个标签，其名为 new_label ，其值为 instance 标签的值的正则匹配的结果
  label_replace(go_goroutines, "new_label", "$1-$2", "instance", "(.*):(.*)")
  ```
  - 如果 new_label 与已有标签同名，则会覆盖它。

#### 算术函数

- 矢量可以使用以下算术函数：
  ```sh
  abs(go_goroutines)                    # 返回每个采样时刻处，数据点的绝对值
  round(go_goroutines)                  # 返回每个采样时刻处，数据点四舍五入之后的整数值
  absent(go_goroutines)                 # 在每个采样时刻处，如果矢量为空（不存在任何数据点），则返回 1 ，否则返回空值
  absent_over_time(go_goroutines[1m])   # 在每个采样时刻处，如果过去 1m 内矢量一直为空，则返回 1 ，否则返回空值
  changes(go_goroutines[1m])            # 返回每个采样时刻处，最近 1m 内数值变化的次数
  resets(go_goroutines[1m])             # 返回每个采样时刻处，过去 1m 内数值减少的次数

  delta(go_goroutines[1m])              # 返回每个采样时刻处，过去 1m 内最新的值减去最旧的值之差
  idelta(go_goroutines[1m])             # 返回每个采样时刻处，过去 1m 内最新两个数据点的差值
  deriv(go_goroutines[1m])              # 通过简单线性回归，计算每秒的导数

  # 以下函数专用于处理 Counter 类型的矢量，即单调递增的矢量。计算结果不会为负
  increase(http_requests_count[1m])     # 返回每个采样时刻处，过去 1m 内的增量
  rate(http_requests_count[1m])         # 返回每个采样时刻处，过去 1m 内的增长率，即平均每秒增量
  irate(http_requests_count[1m])        # 返回每个采样时刻处，过去 1m 内最新两个数据点之间的增长率
  ```
  - 使用函数时，时间范围 `[range]` 应该至少是 scrape_interval 的两倍，否则在过去 range 时长内的数据点可能少于 2 个，导致计算结果为空。
  - rate() 的计算结果，相当于 increase() 除以时间范围 range 。

- 关于 delta()、increase() ：
  - delta() 函数用于计算矢量的差值、变化量。
    - 例如 `delta(http_requests_count[1m])` 的计算结果接近于 `http_requests_count - http_requests_count offset 1m` ，但不完全相同，因为受到 extrapolation 的影响。
  - increase() 函数用于计算矢量的增量，因此希望矢量是单调递增的。如果矢量的值在 range 时长内一会增大一会减小，则累计每一段增量，视作总增量。
    - 假设矢量的值从 30 变为 50 ，则差值、增量都为 20 。
    - 假设矢量的值从 50 变为 40 ，则差值为 -10 ，增量为 40 。这里 increase() 认为 Counter 计数器先从 50 重置到 0 ，然后从 0 增长到 40 ，只是因为离散采样没有采样到 0 值，因此增量为 40-0=40 。
  - 如果矢量为 Counter 类型，即单调递增，则 delta() 与 increase() 的计算结果通常相同。
    - 但 Counter 类型的矢量不能保证总是单调递增，比如 exporter 重启时会重新计数，称为计数器重置（Counter Reset），此时 delta() 与 increase() 的计算结果不同。
    - 如果矢量的值减小，则 delta() 的计算结果可能为负，可以只取 `delta(...) >= 0` 部分的值。而 increase() 的计算结果不会为负，反而会计算出比 delta() 更大的增量，因为每次 Counter Reset 之后会从 0 开始重新计算增量。
  - 综上，选用函数的一般逻辑如下：
    - 如果矢量为 Counter 类型，则用 increase() 计算增量，用 rate() 计算增长率。
    - 如果矢量为 Gauge 类型，则用 delta() 计算差值，用 deriv() 计算导数。

- 关于 idelta()、irate() ：
  - 时间范围 range 越大，rate() 函数的曲线越平缓。而 idelta()、irate() 的曲线总是很尖锐，不受 range 影响，接近瞬时值。
  - range 取值应该尽量大些，因为 range 过大时不影响 idelta()、irate() 的计算精度，但是 range 小于 scrape_interval 的两倍时会缺少数据点。
  - Prometheus 可能因为超时而漏采了一些点，此时如果用 idelta()、irate() 计算矢量每隔 scrape_interval 时长的变化量，则误差较大。

- 例：假设 scrape_interval 为 30s ，指标 http_requests_count 在 2m 时间内采样了 4 个数据点，取值依次为 3、6、9、12 ，进行以下函数计算：
  - `delta(http_requests_count[1m])` 计算结果中，每个数据点的值都为 6 。
  - `idelta(http_requests_count[1m])` 计算结果中，每个数据点的值都为 3 。
  - `increase(http_requests_count[1m])` 计算结果中，每个数据点的值都为 6 。
  - `rate(http_requests_count[1m])` 计算结果中，每个数据点的值都为 0.1 。
  - `irate(http_requests_count[1m])` 计算结果中，每个数据点的值都为 0.1 。

- 例：假设 scrape_interval 为 30s ，指标 http_requests_count 在 2m 时间内采样了 4 个数据点，取值依次为 3、1、2、5 ，进行以下函数计算：
  - `delta(http_requests_count[30s])` 计算结果为空，因为 30s 时间内包含的数据点少于 2 个，不能计算差值。
  - `delta(http_requests_count[50s])` 计算结果显示的图像不连续。因为 50s 时间内，有时包含 2 个数据点，就有图像；有时包含 1 个数据点，就没有图像。
  - `delta(http_requests_count[1m])` 计算结果中，第 4 个数据点的值为 (5-2)/30*60=6 ，该值受 extrapolation 影响。
  - `delta(http_requests_count[90s])` 计算结果中，第 4 个数据点的值为 (5-1)/60*90=6 ，该值受 extrapolation 影响。

#### extrapolation

- delta()、increase()、rate() 是数学里常见的函数，但 Prometheus 是离散采样，实现它们存在一定难度、误差。
  - 问题：假设 scrape_interval 为 30s ，执行 `delta(http_requests_count[70s])` ，此时不能找到相距 70s 的两个数据点，如何得出 70s 时长内的差值？
    - 为了解决该问题，Prometheus 采用外推（extrapolation）机制：先计算矢量在 30s 时长内的差值，然后按时间比例放大，得到 70s 时长内的差值。不过这样会产生误差。
  - 问题：假设 scrape_interval 为 30s ，指标 http_requests_count 采样的一组数据点记作 p1、p2、p3、p4 ，执行 `delta(http_requests_count[70s])` 时应该读取几个数据点来计算差值？
    <!-- - 此时 range 大于 scrape_interval 的 2 倍，看起来 Prometheus 在每个 range 时长内可读取 3 个数据点来计算差值。但实际采样间隔不一定等于 scrape_interval ，可能为 31s、35s ，因此每个 range 时长内不一定包含 3 个数据点。保守起见，Prometheus 在每个 range 时长内只读取 `interval/scrape_interval + 0.33 = n` 个数据点，n 向下取整。 -->
    <!-- - 综上，不管 range 是 scrape_interval 的多少倍，函数计算结果都受 extrapolation 影响，会产生误差。 -->

http_requests_count[70s] 会查询到几个 sample ？

<!--
读取大于等于 t0 时刻、小于 t0+0.33*scrape_interval 时刻范围内的所有数据点
ms.Range -->



- 评价 extrapolation 机制：
  - 优点：
    - 用户使用 delta()、increase()、rate() 函数时，可自由调整 range 的大小，方便统计分析。
    - Prometheus 采集监控指标时，即使漏采了少量数据点，也能使用 delta()、increase()、rate() 函数绘制图像。即使未来几分钟的监控指标尚未采集，也能绘制图像，实现预测。
  - 缺点：
    - 如果原指标的值不是匀速变化的，则 range/scrape_interval 比例越小，函数计算结果的误差越大。[相关 Issue](https://github.com/prometheus/prometheus/issues/3746)
    - 即使原指标的值为整数，但受到 extrapolation 的影响，函数计算结果也可能包含小数。
  - 如果用户担心 extrapolation 误差，可采取以下措施：
    - 增加 range 或减小 scrape_interval ，从而增加 range/scrape_interval 比例，能减小 extrapolation 误差。
    - 改用 idelta()、irate() 函数，能避免 extrapolation 误差。


<!--
- 另一个问题：分桶
  - 问题：假设 scrape_interval 为 30s ，指标 http_requests_count 采样的一组数据点为 1、1、2、2、3、3 。


根据 step 将读取的数据点分为多组，默认的 step 等于 range -->

  <!--
  这样少统计了一个 scrape_interval ，，，遗漏了上一个 range 最后一个数据点，与下一个 range 第一个数据点的差值
  解决办法是：缩小查询的步长（step），使得上一个 range 最后一个数据点，重复担任下一个 range 第一个数据点
  -->


- 例：假设 scrape_interval 为 30s ，指标 http_requests_count 采样的一组数据点为 20、30、50、40 。
  - 如果执行 `delta(http_requests_count[1m])` ，则最后一个 scrape_interval 的差值为 40-50=-10 。然后 extrapolate ，得到过去 1m 时间内的差值为 -10/30*60=-20 。
  - 如果执行 `increase(http_requests_count[1m])` ，则最后一个 scrape_interval 的差值为 40-50 ，叠加 Counter Reset 之前的值 50 ，得到增量为 40-50+50=40 。然后 extrapolate ，得到过去 1m 时间内的增量为 40/30*60=80 。
  - 如果执行 `rate(http_requests_count[2m])` ，则过去 90s 时间内的增长率为 (40-20+50)/90≈0.78 。然后 extrapolate ，将它视作过去 2m 时间内的增长率。

- 下面分析 Prometheus 的 [相关源码](https://github.com/prometheus/prometheus/blob/main/promql/functions.go) ：
  ```golang
  func extrapolatedRate(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper, isCounter, isRate bool) Vector {
      var (
          samples = ...       // range 时长内采样的全部数据点，保存为一个数组
          rangeStart = ...    // range 的开始时刻
          rangeEnd = ...      // range 的结束时刻
          resultFloat float64 // 记录 extrapolatedRate() 函数的计算结果，可能是差值、增长率、增量三种类型
      )

      // 如果采样的数据点少于 2 个，则不能计算差值，结束执行 extrapolatedRate()
      if len(samples.Floats) < 2 {
          return enh.Out
      }

      // 计算指标差值
      numSamplesMinusOne = len(samples) - 1
      first_sample = samples[0]                            // 采样的第一个数据点
      last_sample = samples[numSamplesMinusOne]            // 采样的最后一个数据点
      resultFloat = last_sample.Value - first_sample.Value

      // 以上的 resultFloat 只是计算首尾两个数据点的差值，满足了 delta() 函数的需求。但 increase()、rate() 函数用于处理 Counter 类型的指标，需要考虑 Counter Reset 的情况
      // 如果指标为 Counter 类型，则遍历所有数据点的 value 。如果当前 value 小于 prevValue ，则认为发生了一次 Counter Reset ，为了补偿 resultFloat ，给它叠加 prevValue
      if isCounter {
          prevValue := samples[0].Value
          for _, currPoint  := range samples[1:] {
              if currPoint .Value < prevValue {
                  resultFloat += prevValue
              }
              prevValue = currPoint.F
          }
      }

      // 计算 extrapolation 阈值
      sampledInterval := last_sample.Time - first_sample.Time               // 采样的时长
      averageDurationBetweenSamples := sampledInterval / numSamplesMinusOne // 数据点之间的平均采样间隔。如果因为超时而漏采了一些点，则平均采样间隔会大于 scrape_interval
      extrapolationThreshold := averageDurationBetweenSamples * 1.1         // 触发 extrapolation 的阈值
      extrapolateToInterval := sampledInterval

      // 如果数据点距离 rangeStart、rangeEnd 较近，则将 sampledInterval 时长内的指标差值，按时间比例放大，视作 extrapolateToInterval 时长内的指标差值
      // 如果距离超过 extrapolationThreshold 阈值（大概为 1.1 倍 scrape_interval ），则只放大少量时间（大概为 0.5 倍 scrape_interval ）。否则只采集了 1m 时间的指标，却可以计算 1h 时间的增量，误差很大，不可信
      durationToStart := first_sample.Time - rangeStart   // 第一个数据点距离 rangeStart 的时长
      durationToEnd   := last_sample.Time - rangeEnd      // 最后一个数据点距离 rangeEnd 的时长
      if durationToStart < extrapolationThreshold {
          extrapolateToInterval += durationToStart
      } else {
          extrapolateToInterval += averageDurationBetweenSamples / 2
      }
      if durationToEnd < extrapolationThreshold {
          extrapolateToInterval += durationToEnd
      } else {
          extrapolateToInterval += averageDurationBetweenSamples / 2
      }

      // 按时间比例放大 resultFloat
      factor := extrapolateToInterval / sampledInterval
      resultFloat *= factor

      // 如果正在执行 rate() 函数，则将差值除以时长，得到增长率
      if isRate {
          resultFloat /= sampledInterval
      }

      ...
  }

  // delta() 函数调用 extrapolatedRate() 时会声明 isCounter=false, isRate=false
  func funcDelta(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector {
      return extrapolatedRate(vals, args, enh, false, false)
  }

  func funcRate(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector {
      return extrapolatedRate(vals, args, enh, true, true)
  }

  func funcIncrease(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector {
      return extrapolatedRate(vals, args, enh, true, false)
  }
  ```
  - delta()、increase()、rate() 函数在底层都是调用 extrapolatedRate() 函数，从而计算差值、增量、增长率。
  - delta() 函数只需要计算首尾两个数据点的差值，而 increase()、rate() 函数需要遍历所有数据点的值，开销更大。

#### 聚合函数

- 如果矢量包含多个时间序列，用算术函数会分别对这些时间序列进行运算，而用聚合函数会将它们合并成一个或多个时间序列。
- 矢量可以使用以下聚合函数：
  ```sh
  # 基本统计
  count(go_goroutines)                  # 返回每个采样时刻处，该矢量的数据点的数量（即包含几个时间序列）
  count_values("value", go_goroutines)  # 返回每个采样时刻处，各种值的数据点的数量，并按 {value="x"} 的命名格式生成多个时间序列
  sum(go_goroutines)                    # 返回每个采样时刻处，所有数据点的总和（即将曲线图中所有曲线叠加为一条曲线）
  min(go_goroutines)                    # 返回每个采样时刻处，数据点的最小值
  max(go_goroutines)                    # 返回每个采样时刻处，数据点的最大值
  avg(go_goroutines)                    # 返回每个采样时刻处，数据点的平均值

  # 高级统计
  stddev(go_goroutines)                 # 返回每个采样时刻处，数据点之间的标准差
  stdvar(go_goroutines)                 # 返回每个采样时刻处，数据点之间的方差
  topk(3, go_goroutines)                # 返回每个采样时刻处，最大的 3 个数据点
  bottomk(3, go_goroutines)             # 返回每个采样时刻处，最小的 3 个数据点
  quantile(0.5, go_goroutines)          # 返回每个采样时刻处，大小排在 50% 位置处的数据点

  # 修改数据点的值
  last_over_time(go_goroutines[1m])     # 返回每个采样时刻处，过去 1m 内最新数据点的值
  group(go_goroutines)                  # 将每个数据点的取值置为 1
  sgn(go_goroutines)                    # 判断每个数据点取值的正负。如果为正数、负数、0 ，则分别置为 1、-1、0
  clamp(go_goroutines, 0, 10)           # 限制每个数据点取值的最小值、最大值，语法为 clamp(vector, min, max)
  clamp_min(go_goroutines, 0)           # 限制最小值
  clamp_max(go_goroutines, 10)          # 限制最大值
  ```
  - 聚合函数默认不支持输入有限时间范围内的矢量，需要使用带 `_over_time` 后缀的函数，如下：
    ```sh
    sum_over_time(go_goroutines[1m])    # 返回每个采样时刻处，过去 1m 内数据点的总和（分别计算每个时间序列）
    avg_over_time(go_goroutines[1m])    # 返回每个采样时刻处，过去 1m 内的平均值
    ```
  - 聚合函数可以与关键字 by、without 组合使用，如下：
    ```sh
    sum(go_goroutines) by(job)          # 将所有曲线按 job 标签的值分组，分别执行 sum() 函数
    sum(go_goroutines) without(job)     # 将所有曲线按除了 job 以外的标签分组，分别执行 sum() 函数
    sum(go_goroutines) by(Time)         # Time 是隐式 label ，这里相当于 sum(go_goroutines)
    ```
