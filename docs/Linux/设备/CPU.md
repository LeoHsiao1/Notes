# CPU

- CPU（Central Processing Unit，中央处理单元），又称为中央处理器（Central Processor）。是计算机的核心元件，负责执行指令、运行软件程序。

## 硬件结构

### 计算机结构

- 1945 年，冯·诺依曼（Von Neumann）在论文中提出了一种可以存储指令并执行的计算机结构，被称为冯·诺依曼结构，是目前最流行的计算机结构。
- 冯诺依曼结构在逻辑上分为五个部分：
  - 运算器（Arithmetic Unit）
    - ：负责执行指令、进行运算。
    - 核心部件是算术逻辑单元（Arithmetic Logic Unit ，ALU），能进行算术运算、逻辑运算、位运算等操作。
    - 运算结果会保存到存储器中，或者暂存在累加器中。
  - 控制器（Control Unit）
    - ：负责从存储器读取指令，进行译码分析（即编码的逆过程），然后调用相关部件执行该指令。
    - 例如读取到一个跟运算相关的指令，就取出操作数，发送到运算器进行运算。
  - 存储器（Memory Unit）
    - ：负责用于存储数据和指令。
    - 主要分为内部存储器、外部存储器两种，简称为内存、外存。
  - 输入设备
    - ：负责接收用户或其它设备输入的信息，转换成计算机能识别的数据，然后保存到存储器中。
    - 例如鼠标、键盘。
  - 输出设备
    - ：负责将计算机的数据转换成适当形式的信息，输出给用户或其它设备。
    - 例如显示屏、打印机。
    - 输入、输出设备统称为 IO 设备。

### 主板

- 现代计算机的各个硬件通常集成在一大块集成电路板上，称为主板。其核心元件为 CPU ，是一小块芯片。
- 主板上，CPU 与其它元件之间通过总线进行数据传输。总线根据用途分为三种：
  - 地址总线（Address Bus）
    - ：用于传输地址信息。
    - 只能单向传输，只支持 CPU 发送信号到存储器或 I/O 接口电路。
    - 地址总线的宽度决定了 CPU 直接寻址的最大范围。例如 8 位机的地址总线由 16 根线组成，可以并行传输 16 bits 的信号，因此 CPU 最大可以对 2^16 个存储单元进行直接寻址。
      - 如果存储单元的数量超过该范围，CPU 就无法访问超过的部分。
      - 内存每个存储单元的大小为 1 Byte ，因此 8 位机最多使用 2^16/1024=64 KB 的内存空间。同理，32 位机最多使用 2^32=4 GB 的内存空间。
  - 控制总线（Control Bus）
    - ：用于传输 CPU 对其它部件的控制信号，以及其它部件的应答、请求等信号，支持双向传输。
  - 数据总线（Data Bus）
    - ：用于传输数据，支持双向传输。
    - 数据总线的宽度通常是字长的倍数。

### 寄存器

- 寄存器（Register）：是 CPU 内置的一些容量很小、读写速度超快的存储器，用于暂存 CPU 当前处理的数据、指令。
  - 断电时会丢失数据。

- 寄存器根据用途分为多种类型：
  - 数据寄存器
    - ：用于暂存一些通用的数据。
    - 例如 8086 CPU 有多个 16 位的数据寄存器 AX、BX、CX、DX 。每个寄存器也可分为两个 8 位的寄存器使用，比如将 AX 分为成 AH、AL 。
  - 段寄存器
    - ：用于暂存程序的代码段、数据段、栈等内容。
  - 指令指针寄存器（Instruction Pointer）
    - ：用于暂存 CPU 下一条待执行指令在代码寄存器中的偏移地址。
  - 标志位寄存器（Flag）
    - ：用一组二进制位记录当前指令的执行状态。
    - 例：
      - CF（Carry Flag ，进位标志）：若加减运算时，最高位向前发生了进位或借位，则设置 CF=1 ，否则为 0 。只有两个操作数为无符号数时 CF 标志才有意义。
      - SF（Sign Flag ，符号标志）：若运算结果的最高位为 1 ，则设置 SF=1 ，表示负数。只有两个操作数为带符号数时 SF 标志才有意义。
      - OF（Overflow Flag ，溢出标志）：若运算结果发生了溢出，则设置 OF=1 ，表示运算结果错误。只有两个操作数为带符号数时 OF 标志才有意义。
      - IF（Interrupt Flag ，中断标志）：若设置了 IF=1 ，则允许 CPU 响应来自 CPU 外部的可屏蔽中断的中断请求。

- CPU 执行程序的一般过程：
  1. 从磁盘读取程序，载入内存。
  2. 从内存或缓存读取程序，载入寄存器。
  3. 从寄存器读取程序，解析成指令，然后执行。
      - 执行过程中，如果需要用到某些数据，则从内存载入。
      - 执行过程中，可能发生上下文切换，转去执行其它程序。

### Cache

：CPU 芯片中的一个高速存储器，用于缓存 CPU 从内存经常读取的部分数据。

- CPU 执行某个指令时，如果需要读取某数据，会先尝试到 Cache 中查找该数据。此时分为两种情况：
  - Cache Hit ：在 Cache 中找到了，则可以立即读取该数据。
    - 内核会根据 LRU 算法来自动清理缓存的数据，提高 CPU 读取数据时的 Hit 命中率。
  - Cache Miss ：在 Cache 中没找到，则到内存中查找该数据。

- 目前的 CPU Cache 一般采用 SRAM 介质，容量为几 MB 。
  - 通常存在多级缓存。例如 L1、L2、L3 三级缓存：
    - CPU 先到 L1 Cache 中读取数据，如果 Miss 了再到 L2 Cache 中读取数据，以此类推。
    - L1、L2、L3 Cache 的读写速度大概为 500 GB/s 、300 GB/s 、200 GB/s 。
  - 多核 CPU 一般各有一个独立的 L1 缓存，然后共享同一个 L2、L3 缓存。
  - 例：查看本机的 CPU Cache 容量
    ```sh
    [root@CentOS ~]# lscpu | grep cache
    L1d cache:             32K
    L1i cache:             32K
    L2 cache:              1024K
    L3 cache:              36608K
    ```

### Write Buffer

：CPU 芯片中的一个高速存储器，用于缓冲 CPU 写入内存的所有数据。
- 优点：让 CPU 与内存异步工作，减少等待内存 IO 的耗时。

### 多核心

- 现代 CPU 的时钟频率通常为 3~4 GHz ，执行指令的速度存在上限。为了更快地执行指令，通常在一个物理 CPU 芯片中包含多个核心（Core）处理器，从而能并发执行多个指令。简称为多核 CPU 。
  - Core 的数量通常是偶数。
  - 每个 Core 独立工作，分别包含一份运算器、控制器、寄存器、缓存等元件。
  - 每个 Core 通常分别包含一份 L1~L2 缓存，共用一份 L3~L4 缓存。
- 常见架构：
  - 对称多处理器（Symmetric Multi-Processor ，SMP）
    - ：各个 CPU 之间平等，共享内存、IO 设备等资源。
    - 同时只能有一个 CPU 通过内存总线访问内存，因此 CPU 为 2~4 核时的利用率最高。增加 CPU 数量时，则 CPU 越来越可能因为等待访问内存而阻塞，导致利用率越来越低。
  - 非一致内存访问（Non-Uniform Memory Access ，NUMA）
    - ：在计算机中划分多个节点（node），每个节点包含多核 CPU 、独立内存。
    - 各节点的 CPU 可以并发访问本节点的内存，也可以通过互联模块访问其它节点的内存，但比本地内存的访问速度慢。
    - SMP 属于一致内存访问。而 NUMA 大幅提高了 CPU 利用率，但跨节点访问内存时慢。
  - 大规模并行处理（Massive Parallel Processing ，MPP）
    - ：将多个 SMP 服务器通过网络连通，组成一个计算机系统。
    - 与 NUMA 相比，MPP 不存在跨节点的内存访问。增加 CPU 时，系统性能会线性提升。

- 例：查看本机的 NUMA 节点
  ```sh
  [root@CentOS ~]# lscpu | grep NUMA
  NUMA node(s):          2
  NUMA node0 CPU(s):     0-15
  NUMA node1 CPU(s):     16-31
  ```
  - 上例中有 2 个 NUMA 节点，分别包含 16 核 CPU 。
  - 如果只有 1 个 NUMA 节点，则属于 SMP 架构。

## 型号

### x86

- ：美国 Intel 公司发布的一系列 CPU 型号。
  - 指令集属于 CISC 。
  - x86 CPU 的对外授权较少，主要由 Intel 公司与 AMD 公司交叉授权，两家公司掌控了设计、生产、销售 CPU 的全部流程。
    - 有些技术专利已过期，任何公司都可以使用。
- 1987 年，Intel 公司发布了 8086 型号的 CPU ，被 IBM PC 采用而流行起来。此后的 80186、80286、80386 等型号的 CPU 都沿用这种架构，它们都以 86 结尾，因此称为 x86 架构。
  - 8086 CPU 的字长为 16 ，地址总线的宽度为 20 bits ，数据总线的宽度为 16 bits 。
  - 80386 CPU 的字长为 32 。
- 2003 年，AMD 公司将 x86 架构的字长扩展为 64 ，命名为 AMD64 ，又称为 x86_64、x64 。

### ARM

- ：进阶精简指令集机器（Advanced RISC Machine），指英国 ARM 公司发布的一系列 CPU 型号。
  - 字长为 32 ，指令集属于 RISC 。
  - 成本低、功耗低、散热低，因此用于手机、平板等小型电子设备比 x86 更有竞争力。
  - ARM 公司只负责设计 ARM CPU 架构、指令集，不实际生产 CPU ，而是并出售许可证给其它公司，允许其研发、生产 ARM 芯片。
- 2011 年，ARM 公司发布了 ARMv8-A 架构，字长为 64 ，并且重新实现了 ARM 32 位的指令集。
  - ARMv8-A 架构划分了 AArch32、AArch64 两种执行状态，分别用于执行 32 位、64 位的指令。
- 2020 年，Apple 公司发布了一款基于 ARMv8-A 架构的 CPU ，称为 Apple Silicon M1 ，用于此后的 MacBook、iPad 等设备。

## 指令

- 指令：是让 CPU 进行某一操作的命令代码，由操作码和操作数组成。
  - 操作码：表示操作符即该操作的类型，比如数据传送、算术运算、逻辑运算、位运算等。
  - 操作数：表示该操作的对象，或者对象的地址。
    - 有的指令没有操作数，有的指令有 1 个操作数，有的指令有 2 个操作数。
  - 8086 CPU 的指令示例：
    ```nasm
    MOV   AL, 18H     ; 将源操作数 18H 存入目的操作数中，这里的目的操作数是一个数据寄存器 AL
    ADD   AL, 01H     ; 加法：计算目的操作数 AL 加上源操作数，结果存入目的操作数所指的寄存器中
    SUB   AL, 01H     ; 减法：计算目的操作数 AL 减去源操作数，结果存入目的操作数所指的寄存器中
    INC   AL          ; 增量：使操作数的值加 1
    MUL   2H          ; 无符号数的乘法：计算 AX 中的值乘以该操作数，结果存入 AX
    DIV   2H          ; 无符号数的除法：计算 AX 中的值除以该操作数，结果存入 AX
    ```

- 现代计算机中，运行一个程序时，需要将该程序编译成二进制代码，载入物理内存，让 CPU 读取并执行。
  - 这些二进制代码，实际上是一连串能被本机 CPU 识别的指令，称为指令流。

### 指令集

- 指令集：指某个型号的 CPU 可以识别和执行的所有指令，又称为指令系统。
- 常见的 CPU 指令集架构（Instruction Set Architecture ，ISA）：
  - CISC（Complex Instruction Set Computer ，复杂指令集）

  - RISC（Reduced Instruction Set Computer ，精简指令集）
    - 精简了指令数，每个时钟周期执行一条指令。
    - 指令的长度统一。
    - 精简了寻址方式。

  - EPIC（Explicitly Parallel Instruction Computing ，显式并行指令集）

  - VLIW（Very Long Instruction Word ，超长指令集）

## 调度

- 操作系统中，通常有大量程序同时申请使用 CPU ，如何决定让哪个程序使用 CPU 、使用多长时间？为了解决该问题，通常引入 CPU 调度算法（scheduling algorithm）。
  - 本文分析 CPU 只有 1 个核心时，如何调度。如果 CPU 有多个核心，则需要分别进行调度，问题更复杂些。
  - 类似地，GPU、网卡等资源也可能被多个程序竞争使用，可以采用类似的调度算法。

- 线程是 CPU 调度的基本单位。
  - 从程序的角度来看，启动程序时需要创建至少一个进程，每个进程包含至少一个线程，从而控制该程序的运行状态。
  - 从操作系统的角度来看，决定哪些内存资源给哪个程序使用时，是以进程为单位调度。决定哪些 CPU 资源给哪个程序使用时，是以线程为单位调度。
  - 从 CPU 的角度来看，主要关心操作系统让它执行什么任务（task）。可能一会执行线程 A 的指令流，一会执行线程 B 的指令流。

### 任务

- 每个任务使用 CPU 时，有几种状态：
  - ready ：调用系统接口，请求使用 CPU 。然后阻塞等待，直到轮到它开始使用 CPU 。
    - 通常有多个任务同时请求使用 CPU ，操作系统会将这些 ready 状态的任务放在一个队列中，称为 ready 队列。每次取出一个任务，交给 CPU 执行。
  - running ：正在使用 CPU 。
  - blocked ：任务暂停运行，直到某一条件满足时才继续使用 CPU 。例如等待磁盘 IO 完成。
  - finished ：该任务执行完毕，被删除。

- 相关的几个时间指标：
  - Arrival Time ：任务刚刚进入 ready 队列的时刻。
  - Completion Time ：任务刚刚执行完毕的时刻。
  - Turn Around Time（周转时间）：从 Arrival Time 到 Completion Time 的时长，表示该任务等了多久才执行完。
    - Turn Around Time 分为两部分：
      - Waiting Time ：任务在 ready 队列中等待的时长。
      - Burst Time ：任务被 CPU 执行的时长。
    - 通常一个任务执行完之后，才能知道其 Turn Around Time 时长。不过周期性任务的时长可以预知。

### 算法分类

- 根据能否同时开始多个任务，对调度算法分类：
  - 串行工作（Serial）
    - ：同时只能开始、执行一个任务，执行完之后才能执行下一个任务。
  - 并行工作（Parallel）
    - ：同时开始、执行多个任务。
    - 例如多个线程，可以同时运行在 CPU 的不同核心上，每个核心在串行工作。
  - 并发工作（Concurrent）
    - ：同时只能执行一个任务，但可以同时开始多个任务，交替执行，从而看起来像同时执行。
    - 例如多个线程，可以交替运行在 CPU 的同一核心上。
    - 如何确定多个任务的执行顺序？通常是给每个任务设置一个优先级数值，数值越大则优先执行。

- 根据能否抢占 CPU ，对调度算法分类：
  - 抢占式调度（Preemptive Scheduling）
    - ：允许一个任务正在使用 CPU 时，被其它任务打断（通常是因为其它任务的优先级更高），抢走 CPU 的使用权。
    - 此时，发生了 CPU 上下文切换。抢占者的 context ，从 ready 队列移动到 CPU 寄存器。被抢占者的 context ，从 CPU 寄存器移动到 ready 队列。
    - 这实现了并发工作。
    - 如果一个任务主动放弃使用 CPU ，比如阻塞，则不属于抢占式调度。
    - 静态调度、动态调度都可能允许抢占式调度。
  - 非抢占式调度（Non-Preemptive Scheduling）

- 根据能否改变调度结果，对调度算法分类：
  - 静态调度
    - ：事先安排所有任务的执行顺序、执行时间，不能变化。
  - 动态调度
    - ：可以改变调度结果。
    - 优点：能适应环境的变化。例如出现重要任务时，优先执行。
    - 缺点：运行时需要动态决策，开销更高。

- 根据能否改变任务的优先级，对调度算法分类：
  - 静态优先级
    - ：每个任务在开始之前，优先级就已设定，不能变化。
  - 动态优先级
    - ：每个任务在运行时，优先级可以变化。

### 算法原理

- FCFS（First Come First Serve，先来先服务）
  - 原理：
    1. 事先知道每个任务的 Arrival Time ，从小到大排序。
    2. 每执行完一个任务，就从 ready 队列取出 Arrival Time 最早的一个任务，执行它。
        - 换句话说，以 FIFO（First In First Out，先入先出）的方式取出 ready 队列中的任务。
  - 特点：
    - 非抢占式调度
    - 静态调度
  - 优点：
    - 最简单的算法，容易实现。
  - 缺点：
    - 几乎不控制 CPU 调度过程，功能、性能不如其它算法。
    - 串行工作。排序越靠后的任务，Waiting Time 越久。

- SJF（Shortest Job First，最短任务优先）
  - 原理：
    1. 事先知道每个任务的 Burst Time 。
    2. 每执行完一个任务，就从 ready 队列取出 Burst Time 最小的一个任务，执行它。
        - 如果 Burst Time 最小的任务有多个，如何决策？可以采用 FCFS、RR 等算法。
  - 特点：
    - 非抢占式调度
    - 静态调度
  - 优点：
    - 虽然是串行工作，但 SJF 是使所有任务的平均 Waiting Time 最小的算法，因此平均 Turn Around Time 也最小。
  - 缺点：
    - 难以实现。因为难以事先知道每个任务的 Burst Time 。
    - 公平性差。排序靠后的那部分任务，会饥饿，甚至饿死。

- SRTF（Shortest Remaining Time First，最短剩余时间优先）
  - 原理：
    1. 每隔一定时间，统计每个任务的 Remaining Time 。
        - Remaining Time 表示一个任务还需要被 CPU 执行多久，其值等于 Burst Time 减去已被 CPU 执行的时长。
    2. 每隔一定时间，从所有任务中，找出 Remaining Time 最小的那个任务，执行它。
  - 特点：
    - 抢占式调度
    - 动态调度
  - SRTF 是 SJF 算法的改进版，允许抢占式调度。
    - 假设 CPU 执行任务 A 时，新增一个 Waiting Time 更小的任务 B 。如果仅仅比较 Waiting Time ，就让 CPU 切换执行任务 B ，则没考虑到一种情况：任务 A 可能 Remaining Time 更短，就快执行完了。因此 SJF 不适合抢占式调度。
    - SRTF 是比较所有任务的 Remaining Time ，判断谁能更快执行完毕，因此更合理。

- LJF（Longest Job First，最长任务优先）
  - 原理：与 SJF 相反，是执行 Burst Time 最长的一个任务。
  - 缺点：
    - 容易增加所有任务的平均 Waiting Time 、Turn Around Time 。
    - 公平性差。排序靠后的那部分任务，会饥饿，甚至饿死。
    - 吞吐量极低。

- LRTF（Longest Remaining Time First，最长剩余时间优先）
  - 原理：与 SRTF 相反，是执行 Remaining Time 最长的一个任务。
  - LRTF 是 LJF 算法的改进版，允许抢占式调度。

- HRRN（Highest Response Ratio Next，最高响应率优先）
  - 原理：
    1. 每隔一定时间，统计每个任务的 Response Ratio 。
        - Response Ratio 表示一个任务等待的程度，计算公式为 `(Waiting Time / Burst Time) + 1` 。
    2. 每隔一定时间，从所有任务中，找出 Response Ratio 最大的那个任务，执行它。并且不允许抢占式调度。
  - 特点：
    - 非抢占式调度
    - 动态调度
  - 优点：HRRN 是 SJF 算法的改进版，提高了公平性。
    - 大部分情况下，一个任务的 Burst Time 越小，则 Response Ratio 越大。此时 SJF 与 HRRN 的效果相同。
    - 少部分情况下，一个 Burst Time 较小但不是最小的任务，可能长时间等待执行。此时 SJF 会导致该任务越来越饥饿，而 HRRN 能发现并执行这个饥饿的任务。
  - 缺点：
    - 难以实现。因为难以事先知道每个任务的 Burst Time 。

- EDF（Earliest Deadline First，最早截止时间优先）
  - 原理：
    1. 每隔一定时间，统计每个任务的 Deadline 。比如任务 A ，希望在时刻 t 之前被执行完毕，超时则可能导致任务失败、任务降级。
    2. 每隔一定时间，从所有任务中，找出 Deadline 最早的那个任务，执行它。
  - 特点：
    - 抢占式调度
    - 动态调度
  - 优点：
    - 容易提高 CPU 使用率。如果 CPU 使用率低于 100% ，则说明所有任务都被及时完成，实现了 schedulable 。
    - 公平性好。不管一个任务是否重要，当它即将超时时，都会被优先执行。
    - 实时性好。尽量让每个任务都在一定时间内（通常为毫秒级）执行完毕。
  - 缺点：
    - 如果 CPU 使用率超过 100% ，负载过大，则依然会尽量执行每个即将超时的任务，结果这些任务可能全部超时。不如放弃执行一些次要任务，减轻 CPU 负载。

- RMS（Rate Monotonic Scheduling，速率单调调度）
  - 原理：
    1. 事先知道每个任务的执行周期。
    2. 周期越短的任务（或者说执行频率越高），会被优先执行。
  - 特点：
    - 抢占式调度
    - 静态调度
  - 例：
    - 假设任务 A 平均每隔 10ms 使用 1 单位时长的 CPU ，任务 A 平均每隔 20ms 使用 1 单位时长的 CPU 。则任务 A 的优先级更高。
    - 当任务 A 执行完毕之后，剩余的 CPU 时长才可以分配给任务 B 。如果没有任务需要执行，则 CPU 处于空闲状态。
    - 当任务 A 需要使用 CPU 时，如果 CPU 正在被任务 B 使用，则任务 A 可以抢占式调度。
  - 优点：
    - 处理周期性任务时，RMS 是最高效的算法。
    - 容易预测调度结果，比如预测这组任务是否 schedulable 。
  - 缺点：
    - 难以处理非周期性任务。

- RR（Round Robin，循环赛）
  - 原理：
    1. 将 CPU 可用时长分割成大量时间片段（time slice）。每个时间片段是 CPU 时钟周期的数倍，比如 10ms 。
    2. 将所有任务按 FCFS 算法排序。每个任务使用 CPU 一个时间片段，然后轮到下一个任务。
  - 特点：
    - 抢占式调度。每个任务最多连续使用 CPU 一个时间片段，就会切换执行下一个任务。
  - 优点：
    - 公平性很好。
  - 缺点：
    - 如果循环太慢，则效果接近 FCFS 算法。
    - 如果循环太快，则会频繁发生 CPU 上下文切换，导致平均 Turn Around Time 大，吞吐量低。

- PS（Priority Scheduling，优先级调度）
  - 原理：
    1. 事先给每个任务设定一个 Priority 数值，表示优先级。
    2. 每隔一定时间，从所有任务中，找出 Priority 最大的那个任务，执行它。
        - 如果 Priority 最大的任务有多个，如何决策？可以采用 FCFS、RR 等算法。
        - 如果 CPU 执行一个任务时，新增一个 Priority 更大的任务，则切换执行新任务。
  - 特点：
    - 抢占式调度
    - 动态调度
  - 优点：
    - 算法简单，容易实现。
    - 可控性好。可以人工调整每个任务的 Priority ，从而区分重要任务、次要任务。
  - 缺点：
    - 人工调整 Priority 比较麻烦。
    - 公平性差。Priority 较低的那部分任务，会饥饿，甚至饿死。

- MQS（Multiple Queue Scheduling，多队列调度）
  - 原理：
    1. 划分多个 ready 队列，分别用于存放不同类型的任务。
    2. 每个队列可能包含多个任务，按任一算法，决定当前执行哪个任务。
    3. 多个队列可能同时申请使用 CPU ，按任一算法，决定当前执行哪个队列。此时每个队列相当于一个大型任务。
  - 例：
    - 队列 1 用于存放重要任务，采用 EDF 算法。
    - 队列 2 用于存放次要任务，采用 FCFS 算法。
    - 多个队列之间，采用 RR 等算法。
  - 优点：
    - 可以组合使用多种算法，兼具它们的优点。
    - 可控性好。可以让不同任务，采用不同算法。

- MLFQ（Multilevel Feedback Queue Scheduling，多级反馈队列调度）
  - 1960 年代，麻省理工学院的教授 Corbató 发明了 MLFQ 算法，他是研发分时操作系统的先驱。
  - 原理：
    1. 每个队列内部，可以采用任一算法。
        - 例如优先级高的队列采用 FCFS 算法，优先级低的队列采用 RR 算法。
    2. 多个队列之间，采用 PS 算法。
        - 因此，当优先级高的队列为空时，优先级低的队列才能执行。
    3. 引入了反馈机制：监控每个任务在当前队列的调度效果，如果效果不好，则可以移动到新队列。例如：
        - 新增一个任务时，通常加入优先级最高的那个队列。
        - 如果一个任务已发生了较长的 Burst Time ，却依然没执行完毕，则移动到优先级更低的队列。这样，一个任务可能先后加入队列 1 、队列 2、队列 3 ，优先级依次降低。
        - 如果一个任务已发生了较长的 Waiting Time ，越来越饥饿，则进行老化，移动到优先级更高的队列。
        - 如果一个任务属于 IO 密集型（需要及时读写数据），或交互式任务，则移动到优先级更高的队列。
  - MLFQ 算法是 MQS 算法的改进版。
    - MQS 算法中，每个任务被分配到某个队列之后，就不能移动到其它队列。
    - 而 MLFQ 算法通过反馈机制，改变每个任务所属的队列。
  - 特点：
    - 抢占式调度
    - 动态调度
    - 动态优先级。改变任务所属的队列时，既改变了调度算法，又改变了优先级。
  - 优点：
    - 很灵活，可实现复杂的调度逻辑。
  - 缺点：
    - 算法复杂，调度开销大。
    - 大幅增加了 CPU 上下文切换。

- CFS（Completely Fair Scheduler，完全公平调度）
  - 设计初衷：尽量公平地调度，使得每个任务实际使用的 CPU 时长相等。
  - 原理：
    1. 给每个任务添加一个属性 vruntime ，用于累计该任务已经使用的 CPU 时长，单位为纳秒。
        - 如果新增一个任务，或者一个正在使用 CPU 的任务回到 ready 队列，则将其 vruntime 重置为 min_vruntime 。
    2. 每隔一定时间，将所有任务放在红黑树（rbtree）中，按 vruntime 大小进行排序，使得 vruntime 最小的任务位于 rbtree 最左端。
    3. 每隔一定时间，执行 rbtree 最左端的那个任务。允许抢占式调度。
  - 优点：
    - 比 RR 算法更公平。
      - 因为占用 CPU 时间更短的任务，其 vruntime 更小，会被优先调度。
      - 相比之下，RR 算法是分配相等的 CPU 时长给所有任务，不考虑每个任务实际需要多少 CPU 时长。保证了分配的公平，但结果不一定公平。
    - 比 RR 算法更灵活。能根据所有线程的 vruntime 动态排序，实现动态调度。
    - 比 RR 算法的 Waiting Time 更小。因为新增任务的 vruntime 最小，会很快被调度。

### 算法评价

- 上文介绍了几种 CPU 调度算法。但没有全能的算法，需要根据计算机的实际工作情况，选择一个合适的算法。需要从多个方面评价一个算法的效果：
  - 理想情况下，应该让所有任务在各自的 Deadline 之前，被 CPU 执行完毕。此时，称这组任务是可调度的（schedulable）。
    - 如果 CPU 不能及时执行所有任务，则应该优先执行重要任务。但公平性不能太差，应该保障次要任务也被执行。
  - CPU 使用率
    - ：单位时间内，CPU 被使用时长的占比。
    - 理想情况下，应该不断安排任务让 CPU 执行，让 CPU 使用率接近 100% ，不空闲，不浪费。
  - 吞吐量
    - ：单位时间内，CPU 完成任务的数量。
    - 有的场景希望吞吐量越高越好，比如磁盘 IO 。有的场景不在乎吞吐量。
  - Waiting Time
  - Turn Around Time

- 优先级反转（priority inversion）
  - ：一种调度时的常见问题，是指优先级更低的任务，反而先被执行。
  - 例如等待释放资源时，可能发生优先级反转：
    1. 假设有 3 个任务，优先级为 A > B > C 。
    2. A 执行时，需要使用某个资源，但该资源被 C 占用、尚未释放，于是 CPU 转去执行 C 。
    3. C 在执行时，可能被优先级更高的 B 抢占 CPU 。
    4. 最终，B 优先级比 A 低，却抢占了 CPU 。
  - 对策：
    - 当 A 等待 C 释放资源时，让 C 临时继承 A 的优先级。
    - 给每个资源也分配优先级，当 C 占用一个资源时，会临时提升优先级，与该资源对齐。

- 饥饿（Starvation）
  - ：一种调度时的常见问题，是指优先级最低的部分任务，长时间等待被执行，Waiting Time 很大。
  - 甚至可能不断出现优先级更高的新任务，导致这些饥饿的任务永远不被执行，该现象称为饿死。相当于从活锁，变成了死锁。
  - 对策：
    - 采用 RR 等算法，保障每个任务都会被 CPU 执行。
    - 每隔一定时间，检查所有任务的 Waiting Time 。如果某个任务的 Waiting Time 较长，则按比例提高其优先级。该机制称为老化（Aging）。
  - 通常认为，饥饿的任务越少，则公平性越好。

- 根据 CPU 调度算法的不同，将操作系统分为几类：
  - 批处理系统（Batch Processing System）
    - 特点：串行工作，先提交一批任务，然后等待 CPU 执行完毕。
    - 优点：原理简单。
    - 缺点：不能优先执行重要任务。
    - 常用的调度算法：FCFS、SJF
  - 实时系统（Real Time Operating System，RTOS）
    - 特点：
      - 抢占式调度
      - 实时性
        - ：并发工作，尽量让每个任务都在一定时间内（通常为毫秒级）执行完毕。
        - 细分为两种实时性：
          - 硬实时：如果超过时间，则任务失败。
          - 软实时：允许不实时，只是服务降级。
        - 优点：及时性、可靠性更好，适合交通、军事等严格要求的场景。
      - 精简
        - ：RTOS 常用于嵌入式设备，可以精简到几 MB 。
        - 有的嵌入式设备采用 Linux 系统，因为功能比 RTOS 更多。
    - 常用的调度算法：EDF、RMS
    - RTOS 系统举例：
      - FreeRTOS
      - RT-Thread
      - VxWorks
      - RTLinux
  - 分时系统（Time Sharing System）
    - 特点：并发工作，将 CPU 可用时长分割成大量时间片段（比如以 10ms 为单位），然后决定每个时间片段分配给哪个任务使用。
    - 优点：每个任务或多或少都能使用 CPU ，比较公平。
    - 缺点：CPU 经常切换执行不同的任务，增加了开销。

### Linux调度器

- Linux 内核的 CPU 调度器，又称为进程调度器（process scheduler），负责决定 CPU 当前执行哪个线程。
  - POSIX 规定以线程（thread）为单位进行 CPU 调度，不过 Linux 内核中的可调度实体是进程，又称为任务（task）。
    - 因此分析 Linux 的 CPU 调度时，可能提到进程、线程、任务三个概念，本质上都是 Linux 进程，用 task_struct 表示。
  - Linux 给每个线程设定了两个属性：
    - 调度策略（scheduling policy）：支持让每个线程采用不同的调度算法。
    - 静态调度优先级（static scheduling priority）：用变量 sched_priority 表示，取值范围为 0~99 。

- Linux CPU 调度的特点：
  - 多队列调度
    - 将所有线程按 sched_priority 取值的不同，划分为多组。同组线程的 sched_priority 相同，组成一个队列。
  - 优先级调度
    - 总是执行当前优先级最高的那个队列（中的线程）。等它执行完毕，队列为空，才能执行优先级较低的队列。
    - 一个队列正在占用 CPU 时，优先级更高的队列可以抢占 CPU 。
  - 静态优先级
    - 调度算法不会改变线程的 sched_priority 。因此同一队列中，不会发生抢占式调度。
    - 不过用户可以调用 `setpriority()` 等系统接口，改变线程的优先级。
  - 抢占式调度
    - 一个线程正在使用 CPU 时，如果出现 sched_priority 更高的其它线程，则总是允许抢占式调度。
  - 混合使用多种调度算法
    - 每个队列中，所有线程最初根据 FIFO 排序，然后根据 policy 调整顺序。
    - 假设某个队列中，一个线程正在占用 CPU ：
      - 如果该线程采用 SCHED_FIFO 策略，则等该线程执行完毕，才会执行队列中的下一个线程。
      - 如果该线程采用 SCHED_RR 策略，则最多连续执行一个时间片段，然后移到队列的尾部。
      - 如果该线程主动释放 CPU ，比如进入 Sleeping 状态，则会移到队列的尾部。
      - 如果被优先级更高的队列抢占 CPU ，则该线程会移到队列的头部，等待继续执行。
    - 改变一个线程的 sched_priority ，则会改变其所属的队列。
      - 如果提高一个线程的 sched_priority ，则会移到新队列的尾部。
      - 如果降低一个线程的 sched_priority ，则会移到新队列的头部。
  - 例：
    - 假设线程 A、B、C 的 sched_priority 分别为 10、0、0 。则线程 A 会一直占用 CPU 的一个核心，而线程 B、C 会按 policy 竞争使用 CPU 的其它核心。

- Linux 的调度策略分为两大类：
  - 实时策略（realtime policy）
    - ：用于处理追求实时性（Real Time，RT）的进程。这些进程的 sched_priority 取值范围为 1~99 。
    - 包含多个调度策略：
      ```sh
      SCHED_FIFO
      SCHED_RR
      SCHED_DEADLINE
      ```
  - 普通策略（normal policy）
    - ：用于处理普通进程。这些进程的 sched_priority 必须取值为 0 。
    - 包含多个调度策略：
      ```sh
      SCHED_NORMAL
      SCHED_BATCH
      SCHED_IDLE
      ```
    - 所有 RT 进程的 sched_priority 都大于普通进程。因此等所有 RT 进程不使用 CPU 时，才允许普通进程使用 CPU 。
    - 常见的几种普通进程：
      - 交互式进程：例如 bash ，需要及时与用户交互，追求较弱的实时性，因此应该分配较高的优先级。
      - 批处理进程：通常不追求实时性，因此可以分配较低的优先级。

- Linux 调度器的演变历史：
  - Linux v0.01 的调度器很简单，只有几十行代码。
    - 原理：采用 RR 算法
      1. 将 CPU 可用时长分割成大量时间片段（time slice），每个时间片段为 150ms 。
      2. 使用一个数组作为队列，记录所有 ready 任务。每个任务使用 CPU 一个时间片段，然后轮到下一个任务。
      3. 定时器每隔 10ms 触发一次中断，检查 CPU 当前执行的任务：
          - 如果当前任务已耗尽一个时间片段，或者已执行完毕，则切换执行下一个任务。
          - 如果当前任务未耗尽一个时间片段，则继续执行。
  - Linux v2.2 定义了三个调度类（scheduling classes），表示三种调度策略：
    ```sh
    SCHED_OTHER # 是每个进程默认采用的调度策略，后来改名为 SCHED_NORMAL
    SCHED_FIFO  # 采用 FCFS 算法。前一个任务执行完毕，才能执行下一个任务
    SCHED_RR    # 采用 RR 算法。每个任务最多连续使用 CPU 一个时间片段（默认为 100ms），然后轮到下一个任务
    ```
  - Linux v2.4 让 SCHED_NORMAL 采用 O(n) 算法。
    - 原理：像 RR 算法。总共有 n 个任务时，需要逐一执行，因此时间复杂度为 O(n) 。
    - 缺点：Waiting Time 较大。
  - Linux v2.6 让 SCHED_NORMAL 采用 O(1) 算法。
    - 原理：总共有 n 个任务时，会在固定时间 t 内执行每个任务一段时间，因此时间复杂度为 O(1) 。
    - 优点：Waiting Time 较小，实时性较好。
  - Linux v2.6.16 添加了 SCHED_BATCH 调度策略。
    - 原理：基于 SCHED_NORMAL ，但每个任务最多连续使用 CPU 一个时间片段，然后轮到下一个任务。
      - 一个时间片段默认为 1.5s 。并且一个任务的优先级越高，其时间片段越长。
    - 优点：减少了抢占式调度，适合批处理任务。
  - 2007 年，Linux v2.6.23 添加了 CFS 调度器，实现了 SCHED_NORMAL、SCHED_BATCH、SCHED_IDLE 三种调度策略。
    - SCHED_IDL 的原理：基于 SCHED_NORMAL ，但优先级比 nice 19 还低。因此当其它队列都为空时，才会执行 SCHED_IDLE 队列。
  - Linux v3.14 添加了 SCHED_DEADLINE 调度策略。
    - 原理：类似于 EDF 算法。属于实时调度策略。


<!-- fork()、clone() 创建进程时，是否会继承当前进程的调度策略、优先级？ -->

<!-- sched_priority 如何被 nice 影响？ -->

  <!-- 2023 年，Linux内核6.6版本开始，CFS 被EEVDF调度器取代 -->






- 相关 API ：
  ```c
  #include <sched.h>

  int sched_getscheduler(pid_t tid);
      // 查询某个 tid 的线程
      // 如果指定 tid=0 ，则会指向调用该函数的当前线程

  int sched_setscheduler(pid_t tid, int policy, const struct sched_param *param);
      // 给某个 tid 的线程，配置调度策略、参数
      // 如果 policy 取值为 SCHED_FIFO、SCHED_RR 实时策略，则 param->sched_priority 取值范围为 1~99
      // 如果 policy 取值为 SCHED_NORMAL 等普通策略，则 param->sched_priority 必须取值为 0

  int sched_yield(void);
      // 主动放弃使用 CPU 。使得调用该函数的当前线程，被移到当前 sched_priority 调度队列的尾部
      // 如果当前 sched_priority 调度队列只有这一个线程，则调用该函数之后，该线程会继续使用 CPU 。此时 CPU 使用率没有提高，反而增加了上下文切换
      // 该函数适用于 SCHED_FIFO、SCHED_RR 实时策略
      // 该函数不建议用于 SCHED_NORMAL 等普通调度策略，因为每个线程经常可能被抢占式调度，没必要主动放弃使用 CPU
  ```



### 优先级

- 如何控制不同进程使用 CPU 的优先级？Linux 使用以下两个参数：
  - Priority
    - 取值范围为 -100~39 ，取值越小表示优先级越高。
    - 对于普通进程，其 Priority = nice + 20 ，取值范围为 0~39 。
    - 对于 RT 类型的进程，其 Priority = -1 - rt_prior ，取值范围为 -100~-1 。
      - rt_prior 取值范围为 0~99 ，取值越大，优先级越高。
  - Nice
    - nice 表示谦让值。如果一个进程增加其 nice ，则会降低优先级，对其它进程更友好。
    - 取值范围为 -20~19 ，默认为 0 。
    - 相关命令：
      ```sh
      ps -eo pid,ni,cmd   # 查看所有进程的 nice 值
      renice <int> <pid>  # 修改一个进程的 nice 值
      ```

<!--
- 除了 sched_priority ，还可以配置其它优先级？
  - nice
    - 对于普通进程，其 param->sched_priority 必须取值为 0 。那么如何区分不同普通进程的优先级？可以修改 param->sched_nice 变量。
    - nice 表示谦让值。取值范围为 -20~19 ，默认为 0 。
    - 如果一个进程的 nice 值增加，则会降低其优先级，对其它进程更友好。

    - 因此普通进程的优先级等于 `priority = 120 + nice`
       因此 static_prio 取值范围为 100~139

 -->




- 相关 API ：
  ```c
  #include <sys/resource.h>

  int getpriority(int which, id_t who);
      // 查询某个对象的 nice 值
      // which 表示该对象的类型，可取值为 PRIO_PROCESS、PRIO_PGRP、PRIO_USER ，表示进程、进程组、用户
      // who 表示该对象的 id

  int setpriority(int which, id_t who, int prio);
      // 设置某个对象的 nice 值
  ```
  - POSIX 规定 nice 值是进程级别的属性。而 Linux 的 NPTL 线程库，配置的 nice 值是线程级别的属性，因此可以给同一进程的各个线程，设置不同的 nice 值。


### 上下文切换

- CPU 中的每个 Core 同时只能执行一个指令。但可以在执行一个指令流的过程中，转去执行其它指令流。该过程称为上下文切换（Context Switch）。
  - 从软件的角度来看：CPU 中的每个 Core 同时只能执行一个程序（表现为一个线程），但 CPU 可以在执行一个程序的过程中，转去执行其它程序。
  - 上下文切换时，需要暂存当前程序的执行信息（主要是寄存器中的内容），称为上下文，以供之后 CPU 跳转回来继续执行。
  - 上下文切换总是会发生，可以提高 CPU 执行多个程序的效率。例如当前程序在等待磁盘 IO 时，就可以转去执行其它程序，避免 CPU 处于空闲。
  - 上下文切换过于频繁时，切换产生的开销也会过大，可能降低 CPU 的总体执行效率。

- CPU 上下文切换分为几种场景：
  - 进程上下文切换
    - CPU 从一个进程转去执行另一个进程时，需要切换寄存器、内核堆栈等内核态资源，以及虚拟内存、全局变量、栈区等用户态资源。
  - 线程上下文切换
    - CPU 从一个线程转去执行另一个线程时，需要切换寄存器、栈区等资源，开销比进程上下文切换小得多。
    - 这里是指在同一进程下切换线程。如果切换到不同进程，则属于进程上下文切换。
  - 系统调用上下文切换
    - 用户态的进程通过调用系统 API 可以切换到内核态执行，此时会发生一次上下文切换。调用结束之后，要继续执行用户态进程，又会发生一次上下文切换。
  - 中断上下文切换
    - 优先级最高，会打断一般进程的执行。
    - 切换时只需要暂存进程的内核态资源，不影响用户态资源。

### 中断

- 中断（interrupt）：指 CPU 在执行一般进程时，突然出现某个重要任务，然后转去执行该重要任务。

- 引发 CPU 中断的原因称为中断源，主要分为两大类：
  - 内部中断：是 CPU 内部的中断，例如除法出错中断、溢出中断、软件中断指令 INT n 。
  - 外部中断：又称为硬件中断，是计算机的其它元件通过 CPU 的芯片引脚传入的中断信号。

- CPU 处理中断的策略：
  - 如果是硬中断，则立即处理其中不能延误的任务，然后将剩下的任务转换成软中断。
  - 软中断通常是不紧急的任务，可以延后处理。比如创建内核线程来处理，该内核线程可能被 CPU 的其它 core 执行。

- 例如，网卡接收数据时会这样触发中断：
  1. 网卡收到一个或多个数据帧，发出一个硬中断，使得网卡驱动程序将数据帧拷贝到内核缓冲区中。
  2. 网卡驱动程序发出一个软中断，使得某个内核线程来解析数据帧，转换成 IP、TCP 等协议包，供监听 Socket 的程序读取。

## 性能指标

### CPU usage

- Linux 内核安排任务给 CPU 执行时，会精确记录每个任务使用 CPU 的时长，便于监控 CPU 的负载大小、使用率。

- 例：查看 CPU 的累计使用时长
  ```sh
  [root@CentOS ~]# cat /proc/stat
  cpu  443710619 3208 169665123 4484368433 32182610 0 127452828 0 0 0   # CPU 所有核心的使用时长之和
  cpu0 202357958 1462 86101880  2258409823 15562055 0 65470261  0 0 0   # 0 号核心的使用时长
  cpu1 241352660 1745 83563242  2225958610 16620554 0 61982566  0 0 0   # 1 号核心的使用时长
  ```
  - 这里的时间单位为 jiffies 。
    - 因为 Linux 内核的定时器，每隔 1 jiffies 时长产生一次中断，监控一次 CPU 。
    - 1 jiffies 通常等于 10 ms 。
  - 这些数值来自 Linux 内存中的计数器。每次 Linux 重启，这些计数器会清零。
  - 这里记录了 10 列数值，表示多种任务使用 CPU 的时长：
    ```sh
    user        # 简称为 us ，表示用户态进程使用的时长，不包括 nice 时长
    nice        # 简称为 ni ，表示 nice 谦让值大于 0 的用户态进程，使用的时长
    system      # 简称为 sy ，表示内核态进程使用的时长
    idle        # 简称为 id ，表示 CPU 的空闲时长，此时没有执行任何任务
    iowait      # 简称为 wa ，表示 CPU 等待磁盘读写数据的时长
    hardware interrupt  # 简称为 irq ，表示硬件中断的时长
    software interrupt  # 简称为 softirq ，表示软件中断的时长
    steal       # 本机作为虚拟机时，被偷走的 CPU 可用时长，会被宿主机用于执行其它任务，比如运行其它虚拟机
    guest       # 本机作为宿主机来运行虚拟机时，虚拟机（称为 guest）中进程使用的 CPU 时长
    guest_nice  # nice 谦让值大于 0 的 guest 进程，使用的 CPU 时长
    ```
  - 分析这么多种 CPU 使用时长比较麻烦，通常只关注一个性能指标：CPU 使用率（CPU usage）
    - 它表示单位时间内，CPU 忙碌时长所占比例。计算公式为 `%CPU = ( 1 - idle时长 / 单位时长 ) × 100%`
    - 假设某一秒，CPU 某个核心的累计 idle 时长增加了 0.2s ，则说明有 0.8s 处于忙碌状态，CPU 使用率为 80% 。
    - 统计 CPU 所有核心的使用率，取平均值，就得到了整个 CPU 芯片的使用率。
    - 用户难以每秒监控一次 `/proc/stat` ，可以每分钟监控一次，计算出每分钟的 CPU 使用率，视作平均每秒的 CPU 使用率。
  - 上面是从 CPU 的角度，统计 CPU 使用时长。而从进程的角度来看，一个进程可能每秒使用多个 CPU 核心，需要累计这些核心的使用时长，才能知道该进程用了多久 CPU 。
    - 假设进程每秒累计使用 1.5s CPU ，则 CPU 使用率为 150% 。
    - 因此，统计进程的 CPU 使用率时，可能超过 100% ，最大值等于 CPU 核数。

- 例：假设在一个宿主机上，运行了两个虚拟机 VM1、VM2 。每秒统计一次 CPU 开销。
  - 假设 VM1 中，CPU 有 2 个核心，平均每秒的 idle 时长为 0.2s、0.4s 。
    - 可知，这 2 个核心，平均每秒的使用时长为 0.8s、0.6s ，合计 1.4s 。
    - 可知，这 2 个核心，平均每秒的 CPU 使用率为 80%、60% 。
    - 可知，整个 CPU 芯片的平均使用率为 70% 。
  - 假设宿主机总共有 2 核物理 CPU ，给 VM1 分配了 2 核虚拟 CPU ，给 VM2 分配了 1 核虚拟 CPU 。
    - 此时，虚拟 CPU 的总核数，超过了物理 CPU 的总核数。这一现象称为超额分配，宿主机不足以让所有虚拟机同时跑满 CPU 。
    - 假设 VM1 中，全部进程的 CPU 使用率为 150% ，则宿主机的物理 CPU 经常处于忙碌状态，每秒只能腾出 0.5s 可用时长给 VM2 。对于 VM2 而言，它的 CPU 可用时长被 steal 了。

### load average

：平均负载，指平均每段时间内活跃的进程数。
- 活跃进程包括：
  - 正在被 CPU 运行的进程（Running）
  - 等待被 CPU 运行的进程（Runnable）
  - 不可中断的进程（比如 iowait）

- 这些活跃进程，使用的系统资源可能不同，主要分为几类：
  - CPU 密集型（CPU intensive）
    - ：进程长时间使用 CPU 进行运算。因此平均负载高时，CPU 使用率也高。
  - IO 密集型（IO intensive）
    - ：进程长时间等待磁盘 IO 或网络 IO 。因此平均负载高时，CPU 使用率不一定高。
    - 一个进程可能同时属于 CPU 密集型、IO 密集型，导致平均负载很高。也可能几乎不用资源，长时间 sleep 。
    - 正常情况下，CPU iowait 会在很短时间内结束。
      - 如果 iowait 长时间较高，可能是磁盘 IO 量太大，或系统发生故障，这会导致某些进程一直处于 D 状态，占用 CPU 。

- 如果只存在 CPU 密集型进程，则理想情况下，主机的平均负载数应该刚好等于 CPU 核数，使得每个 CPU 运行一个活跃进程，且没有 CPU 空闲。
  - 例：对于有 2 核 CPU 的主机，
    - 若平均负载为 1 ，说明 CPU 使用率为 50% 。
    - 若平均负载为 2.6 ，说明 CPU 超载了，有部分进程竞争不到 CPU 。
  - 实际上，除了 CPU 密集型进程，主机中经常存在一些 sleep 状态的进程，不会增加 CPU 使用率，但会导致平均负载看起来虚高。
    - 例如平均负载为 4 时，可能 CPU 使用率为 0% 。

- 通常用 uptime 命令查看 CPU 平均负载。例：
  ```sh
  [root@CentOS ~]# uptime
  up 21 days, 41 min,  1 users,  load average: 0.52, 0.58, 0.59
  ```
  - up 21 days, 41 min ：表示主机的运行时长。每次重启，会重新计时。
  - 1 users ：表示已登录的用户数。
  - load average: 0.52, 0.58, 0.59 ：表示最近 1 分钟、5 分钟、15 分钟的平均负载。

### 执行速度

- 时钟周期（Clock Cycle）
  - ：CPU 的振荡器发出时钟脉冲的间隔时长。
  - 其倒数称为时钟频率。
  - 例：一个 4 GHz 的 CPU ，每秒产生 `4*10^9` 个时钟脉冲，时钟周期为 `0.25*10*-9` 秒。
  - 现代 CPU 的时钟频率通常为 3~4 GHz 。如果继续提升时钟频率，则耗电量、散热难度大幅增加。

- 指令周期
  - ：CPU 执行一条指令所需的时长。
  - 不同指令的指令周期不同，因此通常是计算平均值。
  - 早期的 CPU ，每个时钟周期只能执行一条指令。现代的 CPU ，每个时钟周期可能执行多条指令。
  - 将 CPU 的时钟频率，乘以每个时钟周期平均执行的指令数（Instructions Per Cycle ，IPC），就得到每秒平均执行的指令数（Instructions Per Second ，IPS）。

- 字长（Word Size）
  - ：又称为位元，指 CPU 的算术逻辑单元每次最多能处理多少位二进制数据。
  - 现代 CPU 的字长通常是 32 位、64 位。

### 读写速度

- 假设用 tar 命令压缩文件，则主要流程如下：
  1. 从磁盘的源文件中读取数据，然后依次拷贝到内存、CPU Cache、CPU Register 。
  2. CPU 从 CPU Register 读取源数据，执行压缩算法，计算出压缩后的数据。
  3. CPU 输出压缩后的数据到 CPU Register ，然后依次拷贝到 CPU Cache、内存、磁盘。
  可见，CPU 执行程序的耗时主要受以下因素影响：
  - CPU 读写数据的速度
  - CPU 执行指令的速度

- 计算机中存在多种存储设备，读写速度从高到低分别为：CPU Register > CPU Cache / Buffer >> 内存 >> 磁盘
  - 时钟频率、访问延迟也是这样的顺序。
  - 成本则相反顺序。一般磁盘的 IO 速度最慢，但成本最低，因此相同价格时的容量最大。
  - 除了读写速度的差异，外存在断电之后能持久保存数据，而其它存储设备通常不能。

- CPU 处理数据的速度，比外存读写数据的速度，快很多倍。让 CPU 同步读写外存时，会浪费时间等待 IO 。因此 CPU 采用异步读写，通过内存、Cache 中转数据。
  - 读取文件的流程示例：
    1. CPU 要求读取一个文件，发送指令给磁盘驱动器。然后 CPU 可以执行其它任务，不必浪费时间等待。
    2. 磁盘驱动器寻址到文件数据，拷贝到磁盘驱动器的内部缓冲区。然后发送中断通知 CPU ，于是 CPU 发生上下文切换，回来执行当前任务。
    3. CPU 从磁盘拷贝数据到内存。
        - 先拷贝到内存中的 Page Cache 空间，此时只能被内核态进程访问。
        - 从 Page Cache 拷贝到进程内存空间，此时才能被用户态进程访问。
        - 为了避免 CPU 亲自拷贝数据的耗时，通常在计算机中加入 DMA（Direct Memory Access，直接内存访问）控制器，代替 CPU 接收第 2 步的中断信号，将数据拷贝到 Page Cache ，然后发送中断通知 CPU 。
    3. CPU 从内存拷贝数据到 CPU Cache ，再拷贝到 CPU Register，供 CPU 直接访问。
  - 写入文件的流程相反，先由 CPU 从进程内存空间拷贝数据到 Page Cache ，再由 DMA 拷贝到磁盘。
