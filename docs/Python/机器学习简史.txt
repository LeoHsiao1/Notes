

计算机视觉是深度学习的一种用途，包括目标识别、目标跟踪、图像分割、图像生成等。

AI 内容生成（AI Generated Content，AIGC）技术：泛指使用 AI 自动生成文字、图像、音频、视频、代码等内容，代替人工。


AI 图像生成技术的发展阶段：
- 2015 年，主流的技术是通过基于卷积神经网络的迁移学习，来进行图像风格转换。先对图像内容进行语义分割，再将内容和场景通过线条弯曲、风格迁移等手法，转换成指定艺术风格，类似美颜软件的“滤镜”功能。
- 2016 年，流行的技术是生成对抗网络 GAN（Generative Adversarial Nets）。原理：让生成器网络和判别器网络相互对抗，从而创作出真实度和准确度都更高的全新图像。此时网络上出现了大量“以假乱真”的艺术作品。
  - 但是，GAN也不能摆脱传统AI深度模型的问题：无法理解“逻辑”和“常识”，比如AI能够根据文本关键词把元素堆叠在一起，但因为无法理解隐藏在自然语言背后的逻辑关系，所以经常会画出非常“克苏鲁”的反常识作品。
    解决办法是通过大规模数据和暴力计算训练出大模型。
- 2020 年，Open AI 发布 GPT-3 （Generative Pre-trained Transformer 3），是第三代自然语言处理 (NPL) 系统。
  - GPT-3 的模型使用超过 1750 亿个机器学习参数进行训练，是当时最大的神经网络、最先进的文本生成模型。
- 2022 年，流行的技术是扩散模型，源于 2015 年发表的 diffusion 论文。
  - 扩散模型（diffusion model）：逐步添加随机噪声，将样本图像破坏成一张马赛克图像。然后反转这个噪声过程，让 AI 学习如何将马赛克图像恢复成正常的图像。
  优点：
  - 不需要对抗训练。
  - 生成简单图像时比较可靠，比如背景图、纹理，辅助真人画家的工作，相当于 PS 软件的自动填充功能。
  - 很多 AIGC 软件是开源的、免费使用，不会绘画的用户也可以使用，降低了艺术创作的门槛。
    OpenAI 开源的 Dall-E 2 ，可根据用户输入的文字描述，生成图像。
    英国公司 Stability AI 开源的 Stable Diffusion 模型，可根据用户输入的文字描述，在几秒内自动生成图像。
    Novel AI ：一个闭源的网站。在用户输入一些提示词之后，能基于 GPT 模型自动生成小说，还能基于 Stable Diffusion 模型生成图像。
  缺点：
  - 能快速生成大量可读性高的图像，但依然存在小型瑕疵，比如物体破损、人物表情扭曲。通常要尝试生成几十张图像，才能得到一张没有明显瑕疵的图像。
  - 生成的图像只是在少量方面贴近文字描述，难以符合用户期望，不如真人画家。


AIGC 的问题：
- 数据版权。开发人员通常会从互联网获取大量图片用于训练 AI 模型，未经过画家的同意。
- 创作版权。AIGC 的图像通常跟样本图像的元素、画风相似，相当于抄袭原画家，但如何界定是否抄袭？AIGC 的图像应该分配什么样的版权？
- 如果增加 AIGC 的随机性，则生成的内容难以使用，难以代替真人进行艺术创作。因此只能减少 AIGC 的随机性，做一些重复性工作，比如生成一个人物穿多种服装的设定图。
